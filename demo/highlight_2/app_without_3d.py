import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
import torch
from transformers import pipeline
from moviepy.editor import VideoFileClip, ImageSequenceClip
import tempfile
import os
from PIL import Image

# í™˜ê²½ ì„¤ì •
st.set_page_config(page_title="ê³ ê¸‰ ê³¨í”„ ìŠ¤ìœ™ 3D ë¶„ì„", layout="wide")
st.title("ğŸ¯ í”„ë¡œê¸‰ ê³¨í”„ ìŠ¤ìœ™ 3D ë³€í™˜ ì‹œìŠ¤í…œ")

# ëª¨ë¸ ì´ˆê¸°í™” (CPU ê°•ì œ ì„¤ì •)
import os
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
depth_estimator = pipeline("depth-estimation", model="LiheYoung/depth-anything-large-hf", device="cpu")
pose_estimator = mp.solutions.pose.Pose(static_image_mode=False, model_complexity=2)

def estimate_depth(frame):
    """MiDaS ê¸°ë°˜ ì‹¬ë„ ì¶”ì •"""
    return depth_estimator(frame)["predicted_depth"]

def warp_frame(frame, depth_map, angle):
    """ì‹¬ë„ ë§µ ê¸°ë°˜ í”„ë ˆì„ ë³€í˜•"""
    h, w = frame.shape[:2]
    focal = 0.8 * w
    K = np.array([[focal, 0, w/2], [0, focal, h/2], [0, 0, 1]])
    R = cv2.Rodrigues(np.array([0, np.radians(angle), 0]))[0]
    warp_matrix = K @ R @ np.linalg.inv(K)
    return cv2.warpPerspective(frame, warp_matrix, (w,h), borderMode=cv2.BORDER_REPLICATE)

def process_video(uploaded_file, rotation_speed):
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
        tmp_file.write(uploaded_file.read())
        video_path = tmp_file.name
    
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frames = []
    depth_maps = []
    
    # 1ë‹¨ê³„: ì‹¬ë„ ë§µ & í¬ì¦ˆ ì¶”ì •
    progress_bar = st.progress(0)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    for i in range(total_frames):
        ret, frame = cap.read()
        if not ret: break
        
        # ì‹¬ë„ ì¶”ì • (ê²€ìƒ‰ê²°ê³¼[1][2])
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        depth_map = estimate_depth(Image.fromarray(rgb_frame))
        
        # í¬ì¦ˆ ì¶”ì •
        pose_results = pose_estimator.process(rgb_frame)
        
        frames.append(frame)
        depth_maps.append(depth_map)
        progress_bar.progress((i+1)/total_frames)
    
    # 2ë‹¨ê³„: ë™ì  ì¹´ë©”ë¼ ê²½ë¡œ ìƒì„± (ê²€ìƒ‰ê²°ê³¼[3][4])
    angles = np.linspace(0, 360, len(frames)//rotation_speed)
    
    # 3ë‹¨ê³„: í”„ë ˆì„ ë³€í˜•
    processed_frames = []
    for i, (frame, depth) in enumerate(zip(frames, depth_maps)):
        angle = angles[i % len(angles)]
        warped = warp_frame(frame, depth.numpy(), angle)
        processed_frames.append(warped)
    
    # 4ë‹¨ê³„: ë¹„ë””ì˜¤ ì¬êµ¬ì„±
    output_path = tempfile.mktemp(suffix='.mp4')
    clip = ImageSequenceClip(processed_frames, fps=fps)
    clip.write_videofile(output_path, codec='libx264')
    
    return output_path

# UI êµ¬ì„±
col1, col2 = st.columns([3, 1])
with col1:
    uploaded_file = st.file_uploader("ê³¨í”„ ìŠ¤ìœ™ ë™ì˜ìƒ ì—…ë¡œë“œ", type=['mp4'])
    if uploaded_file:
        st.video(uploaded_file)

with col2:
    rotation_speed = st.slider("íšŒì „ ì†ë„", 1, 10, 3)
    processing_mode = st.selectbox("ì²˜ë¦¬ ëª¨ë“œ", ["ë¡œì»¬ CPU", "í´ë¼ìš°ë“œ GPU"])

if uploaded_file and st.button("ë³€í™˜ ì‹œì‘"):
    with st.spinner("3D ë³€í™˜ ì²˜ë¦¬ ì¤‘..."):
        output_path = process_video(uploaded_file, rotation_speed)
        st.success("ë³€í™˜ ì™„ë£Œ!")
        st.video(output_path)
        os.remove(output_path)
