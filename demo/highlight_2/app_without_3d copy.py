# # app.py

# # --- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ---
# # í„°ë¯¸ë„ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ì„¸ìš”:
# # pip install streamlit opencv-python mediapipe moviepy numpy

# import streamlit as st
# import cv2
# import numpy as np
# from pathlib import Path

# # MediaPipe Pose: ì†ëª© ì¢Œí‘œ ì¶”ì¶œìš©
# try:
#     import mediapipe as mp
# except ImportError:
#     mp = None

# # MoviePy: ìŠ¬ë¡œìš° ëª¨ì…˜ ì²˜ë¦¬ìš©
# try:
#     from moviepy.editor import VideoFileClip, vfx, concatenate_videoclips
# except ImportError:
#     VideoFileClip = None

# st.set_page_config(page_title="ê³¨í”„ ìŠ¤ìœ™ ê¶¤ì  íŠ¸ë˜í‚¹ (ë¹„í•™ìŠµ)", layout="wide")
# st.title("ê³¨í”„ ìŠ¤ìœ™ ìŠ¬ë¡œìš° ëª¨ì…˜ + ê³µÂ·í´ëŸ½ í—¤ë“œ íŠ¸ë˜í‚¹ (í•™ìŠµ ë¶ˆí•„ìš”)")
# st.write(
#     """
#     1) ê³¨í”„ ìŠ¤ìœ™ ì˜ìƒì„ ì—…ë¡œë“œí•˜ë©´,  
#     2) ìŠ¤ìœ™ êµ¬ê°„ì„ ìë™ íƒì§€í•´ ìŠ¬ë¡œìš° ëª¨ì…˜ ì²˜ë¦¬í•˜ê³ ,  
#     3) ìŠ¬ë¡œìš° ëª¨ì…˜ êµ¬ê°„ ë™ì•ˆ **ê³¨í”„ê³µ(í°ìƒ‰ ì›)ê³¼ í´ëŸ½ í—¤ë“œ(ë¹ ë¥´ê²Œ ì›€ì§ì´ëŠ” í¬ì¸íŠ¸)**ë¥¼  
#        HSV ë§ˆìŠ¤í¬ + HoughCircles, ê·¸ë¦¬ê³  ì†ëª© ì¸ê·¼ Optical Flowë¡œ ì¶”ì í•˜ì—¬ ë¶€ë“œëŸ¬ìš´ ê¶¤ì ì„ í‘œì‹œí•©ë‹ˆë‹¤.  
#     4) ê²°ê³¼ ì˜ìƒì„ ì¦‰ì‹œ ì¬ìƒí•˜ê³  ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
#     """
# )

# uploaded_file = st.file_uploader("ê³¨í”„ ìŠ¤ìœ™ ì˜ìƒ ì—…ë¡œë“œ (MP4)", type=["mp4"])
# mode = st.radio(
#     "ìŠ¬ë¡œìš° ëª¨ì…˜ ì²˜ë¦¬ ë°©ì‹",
#     options=["Local (On-device) - MoviePy ìš°ì„  ì‚¬ìš©", "Local (OpenCV í”„ë ˆì„ ì¤‘ë³µ)"],
#     index=0,
#     help="MoviePyê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì˜µì…˜ìœ¼ë¡œ ê¹”ë”í•œ ìŠ¬ë¡œìš° ëª¨ì…˜ì„ ì ìš©í•©ë‹ˆë‹¤."
# )

# if uploaded_file is not None:
#     # (1) ì—…ë¡œë“œëœ ì˜ìƒ ì„ì‹œ ì €ì¥
#     video_path = "input_video.mp4"
#     with open(video_path, "wb") as f:
#         f.write(uploaded_file.getbuffer())
#     st.success("ì˜ìƒ ì—…ë¡œë“œ ì™„ë£Œ! ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

#     # (2) ëª¨ë“  í”„ë ˆì„ ì½ê¸°
#     cap = cv2.VideoCapture(video_path)
#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
#     frames = []
#     success, frame = cap.read()
#     while success:
#         frames.append(frame)
#         success, frame = cap.read()
#     cap.release()

#     if total_frames == 0 or not frames:
#         st.error("ë¹„ë””ì˜¤ ì½ê¸° ì‹¤íŒ¨. ìœ íš¨í•œ MP4 íŒŒì¼ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
#         st.stop()

#     # (3) ìŠ¤ìœ™ êµ¬ê°„ ìë™ íƒì§€ (í”„ë ˆì„ ê°„ í”½ì…€ ì°¨ì´ ê¸°ë°˜)
#     motion = np.zeros(len(frames))
#     prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)
#     for i in range(1, len(frames)):
#         gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)
#         diff = cv2.absdiff(gray, prev_gray)
#         motion[i] = np.sum(diff)
#         prev_gray = gray

#     motion = np.convolve(motion, np.ones(5)/5, mode="same")
#     thresh = np.max(motion) * 0.2
#     mask = motion > thresh
#     if np.any(mask):
#         start_idx = int(np.argmax(mask))
#         end_idx = len(mask) - 1 - int(np.argmax(mask[::-1]))
#     else:
#         start_idx, end_idx = 0, len(frames)-1

#     # MediaPipe Poseê°€ ìˆìœ¼ë©´ follow-through í¬í•¨ì„ ìœ„í•´ ì¡°ê¸ˆ ë” ì—°ì¥
#     if mp is not None:
#         end_idx = min(end_idx + 5, len(frames)-1)

#     start_idx = max(0, start_idx)
#     end_idx = min(len(frames)-1, end_idx)
#     if start_idx >= end_idx:
#         st.warning("ìŠ¤ìœ™ êµ¬ê°„ ê°ì§€ ì‹¤íŒ¨. ì „ì²´ ì˜ìƒ ìŠ¬ë¡œìš° ëª¨ì…˜ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
#         start_idx, end_idx = 0, len(frames)-1

#     start_time = start_idx / fps
#     end_time = end_idx / fps
#     st.write(f"ìŠ¤ìœ™ êµ¬ê°„: **{start_time:.2f}s** â†’ **{end_time:.2f}s** (í”„ë ˆì„ {start_idx}â†’{end_idx})")

#     # (4) ìŠ¬ë¡œìš° ëª¨ì…˜ ì²˜ë¦¬
#     slow_factor = 0.5
#     output_path = "output_no_training.mp4"
#     fourcc = cv2.VideoWriter_fourcc(*"mp4v")
#     h, w = frames[0].shape[:2]

#     if mode.startswith("Local") and VideoFileClip:
#         clip = VideoFileClip(video_path)
#         pre_clip = clip.subclip(0, start_time) if start_idx > 0 else None
#         swing_clip = clip.subclip(start_time, end_time)
#         post_clip = clip.subclip(end_time, clip.duration) if end_idx < len(frames)-1 else None

#         slowed = swing_clip.fx(vfx.speedx, slow_factor)
#         parts = []
#         if pre_clip: parts.append(pre_clip)
#         parts.append(slowed)
#         if post_clip: parts.append(post_clip)

#         final_clip = concatenate_videoclips(parts)
#         temp_slow = "temp_slow.mp4"
#         final_clip.write_videofile(temp_slow, codec="libx264", fps=fps, audio=False)

#         cap2 = cv2.VideoCapture(temp_slow)
#         slow_frames = []
#         suc, fr = cap2.read()
#         while suc:
#             slow_frames.append(fr)
#             suc, fr = cap2.read()
#         cap2.release()
#     else:
#         slow_frames = []
#         dup_cnt = int(1/slow_factor)
#         dup_cnt = max(1, dup_cnt)
#         for i, fr in enumerate(frames):
#             if start_idx <= i <= end_idx:
#                 for _ in range(dup_cnt):
#                     slow_frames.append(fr.copy())
#             else:
#                 slow_frames.append(fr.copy())

#     st.write("ê³µÂ·í´ëŸ½ í—¤ë“œ íŠ¸ë˜í‚¹ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

#     # (5) MediaPipe Pose ì´ˆê¸°í™” (ì†ëª© ì¢Œí‘œ ì´ìš©)
#     pose = None
#     if mp is not None:
#         pose = mp.solutions.pose.Pose(static_image_mode=True)

#     raw_club = []  # í´ëŸ½ ë ì¢Œí‘œ ê¸°ë¡ (u,v)
#     raw_ball = []  # ê³¨í”„ê³µ ì¢Œí‘œ ê¸°ë¡ (u,v)

#     # --- HoughCircles / HSV ë§ˆìŠ¤í¬ íŒŒë¼ë¯¸í„° (ê³¨í”„ê³µ) ---
#     # ê³µì€ í™”ë©´ í•˜ë‹¨ ì¤‘ì•™ 30% ë†’ì´ì— í°ìƒ‰ ì›ì´ë¯€ë¡œ HSV ë²”ìœ„ë¥¼ íƒ€ì´íŠ¸í•˜ê²Œ
#     lower_white = np.array([0, 0, 200], dtype=np.uint8)
#     upper_white = np.array([180, 50, 255], dtype=np.uint8)
#     hough_dp = 1.2
#     hough_minDist = 20
#     hough_param1 = 50
#     hough_param2 = 30
#     hough_minR = 4
#     hough_maxR = 15

#     # (6) Optical Flow / Shi-Tomasi íŒŒë¼ë¯¸í„° (í´ëŸ½ í—¤ë“œ)
#     feature_params = dict(maxCorners=50, qualityLevel=0.3, minDistance=7, blockSize=7)
#     lk_params = dict(winSize=(15, 15), maxLevel=2,
#                      criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

#     prev_gray_roi = None  # í´ëŸ½ í—¤ë“œ ì¶”ì ìš© ì´ì „ ROI ê·¸ë ˆì´ìŠ¤ì¼€ì¼

#     for i, fr in enumerate(slow_frames):
#         club_pt = None
#         ball_pt = None

#         # (5-A) í´ëŸ½ í—¤ë“œ: ì†ëª© ì¸ê·¼ 100Ã—100 ROIì—ì„œ Optical Flow ì¶”ì 
#         if pose is not None:
#             rgb = cv2.cvtColor(fr, cv2.COLOR_BGR2RGB)
#             res = pose.process(rgb)
#             if res.pose_landmarks:
#                 lm = res.pose_landmarks.landmark
#                 # ì˜¤ë¥¸ì†ëª© (index=16)
#                 wx = int(lm[16].x * w)
#                 wy = int(lm[16].y * h)

#                 # ROI ì •ì˜ (frame ê²½ê³„ë¥¼ ë„˜ì§€ ì•Šë„ë¡)
#                 x0 = max(0, wx - 50)
#                 y0 = max(0, wy - 50)
#                 x1 = min(w, wx + 50)
#                 y1 = min(h, wy + 50)

#                 roi = fr[y0:y1, x0:x1]
#                 gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

#                 if prev_gray_roi is not None and gray_roi.shape == prev_gray_roi.shape:
#                     # ROI ë‚´ì—ì„œ Shi-Tomasi ì½”ë„ˆ ê²€ì¶œ
#                     p0 = cv2.goodFeaturesToTrack(prev_gray_roi, mask=None, **feature_params)
#                     if p0 is not None:
#                         # Lucasâ€“Kanade Optical Flow ê³„ì‚°
#                         p1, stt, err = cv2.calcOpticalFlowPyrLK(prev_gray_roi, gray_roi, p0, None, **lk_params)
#                         # ì´ë™ ë²¡í„° ì¤‘ ê°€ì¥ í° ê±°ë¦¬(ë²¡í„° í¬ê¸°) í¬ì¸íŠ¸ë¥¼ ê³¨ë¼ í´ëŸ½ í—¤ë“œë¡œ ê°„ì£¼
#                         if p1 is not None:
#                             max_dist = 0
#                             best_pt = None
#                             for (new, old), s in zip(zip(p1.reshape(-1,2), p0.reshape(-1,2)), stt.flatten()):
#                                 if s == 1:
#                                     dx, dy = new[0]-old[0], new[1]-old[1]
#                                     dist = dx*dx + dy*dy
#                                     if dist > max_dist:
#                                         max_dist = dist
#                                         best_pt = new
#                             if best_pt is not None:
#                                 bx = int(best_pt[0]) + x0
#                                 by = int(best_pt[1]) + y0
#                                 club_pt = (bx, by)

#                 prev_gray_roi = gray_roi.copy()
#             else:
#                 prev_gray_roi = None
#         else:
#             prev_gray_roi = None

#         raw_club.append(club_pt)

#         # (5-B) ê³¨í”„ê³µ: HSV ë§ˆìŠ¤í¬ + HoughCircles
#         # í™”ë©´ í•˜ë‹¨ ì¤‘ì•™ 30% ë²”ìœ„ ì œí•œ
#         y_start = int(h * 0.7)
#         x_start = int(w * 0.3)
#         x_end = int(w * 0.7)
#         roi2 = fr[y_start:h, x_start:x_end]

#         hsv = cv2.cvtColor(roi2, cv2.COLOR_BGR2HSV)
#         mask = cv2.inRange(hsv, lower_white, upper_white)
#         # ëª¨í´ë¡œì§€ë¡œ ë…¸ì´ì¦ˆ ì œê±°
#         mask = cv2.medianBlur(mask, 5)

#         circles = cv2.HoughCircles(mask, cv2.HOUGH_GRADIENT, dp=hough_dp, minDist=hough_minDist,
#                                    param1=hough_param1, param2=hough_param2,
#                                    minRadius=hough_minR, maxRadius=hough_maxR)
#         if circles is not None:
#             circles = np.uint16(np.around(circles))
#             # ROI ë‚´ë¶€ì—ì„œ yê°€ ê°€ì¥ í° (í™”ë©´ í•˜ë‹¨ì— ê°€ê¹Œìš´) ì› ì„ íƒ
#             best = None
#             best_y = -1
#             for c in circles[0]:
#                 cx_r, cy_r, r = c
#                 if cy_r > best_y:
#                     best_y = cy_r
#                     best = (cx_r, cy_r, r)
#             if best is not None:
#                 cx, cy, r = best
#                 cx_full = cx + x_start
#                 cy_full = cy + y_start
#                 ball_pt = (cx_full, cy_full)
#         raw_ball.append(ball_pt)

#     if pose is not None:
#         pose.close()

#     # (6) ê¶¤ì  ë³´ê°„(ìŠ¤ë¬´ë”©)
#     def smooth_points(raw_pts, window=5):
#         filled = []
#         last = None
#         for p in raw_pts:
#             if p is not None:
#                 last = p
#                 filled.append(p)
#             else:
#                 filled.append(last)
#         smoothed = []
#         for i in range(len(filled)):
#             xs, ys = [], []
#             for j in range(i - window//2, i + window//2 + 1):
#                 if 0 <= j < len(filled) and filled[j] is not None:
#                     xs.append(filled[j][0])
#                     ys.append(filled[j][1])
#             if xs and ys:
#                 smoothed.append((int(sum(xs)/len(xs)), int(sum(ys)/len(ys))))
#             else:
#                 smoothed.append(None)
#         return smoothed

#     smooth_club = smooth_points(raw_club)
#     smooth_ball = smooth_points(raw_ball)

#     # (7) ê¶¤ì  ì˜¤ë²„ë ˆì´
#     annotated = []
#     past_club = []
#     past_ball = []
#     for idx, fr in enumerate(slow_frames):
#         canvas = fr.copy()

#         # í´ëŸ½ ê¶¤ì  (íŒŒë€ìƒ‰)
#         if smooth_club[idx] is not None:
#             past_club.append(smooth_club[idx])
#         if len(past_club) >= 2:
#             pts = np.array(past_club, dtype=np.int32)
#             cv2.polylines(canvas, [pts], isClosed=False, color=(255, 0, 0), thickness=2)
#         if past_club and past_club[-1] is not None:
#             cv2.circle(canvas, past_club[-1], 5, (255, 0, 0), -1)

#         # ê³µ ê¶¤ì  (ë¹¨ê°„ìƒ‰)
#         if smooth_ball[idx] is not None:
#             past_ball.append(smooth_ball[idx])
#         if len(past_ball) >= 2:
#             pts_b = np.array(past_ball, dtype=np.int32)
#             cv2.polylines(canvas, [pts_b], isClosed=False, color=(0, 0, 255), thickness=2)
#         if raw_ball[idx] is not None:
#             bx, by = raw_ball[idx]
#             cv2.circle(canvas, (bx, by), 5, (0, 0, 255), -1)

#         annotated.append(canvas)

#     # (8) ìµœì¢… ì˜ìƒ ì €ì¥
#     out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))
#     for fr in annotated:
#         out.write(fr)
#     out.release()

#     # (9) ì¦‰ì‹œ ì¬ìƒ & ë‹¤ìš´ë¡œë“œ
#     if Path(output_path).exists():
#         st.video(output_path)
#         with open(output_path, "rb") as f:
#             data = f.read()
#         st.download_button(
#             "ìµœì¢… ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
#             data=data,
#             file_name="swing_slowmo_no_training.mp4",
#             mime="video/mp4"
#         )
#     else:
#         st.error("ê²°ê³¼ ì˜ìƒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.animation as animation
from moviepy.editor import VideoFileClip, ImageSequenceClip
import tempfile
import os
from io import BytesIO
import requests
import json

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê³¨í”„ ìŠ¤ìœ™ 3D ë¶„ì„ê¸°",
    page_icon="â›³",
    layout="wide"
)

st.title("â›³ ê³¨í”„ ìŠ¤ìœ™ 3D ë™ì˜ìƒ ë³€í™˜ê¸°")
st.markdown("ìŠ¤ë§ˆíŠ¸í°ìœ¼ë¡œ ì´¬ì˜í•œ ê³¨í”„ ìŠ¤ìœ™ì„ 3D ì¹´ë©”ë¼ íŠ¸ë˜í‚¹ ì˜ìƒìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("ì„¤ì •")
processing_mode = st.sidebar.selectbox(
    "ì²˜ë¦¬ ë°©ì‹ ì„ íƒ",
    ["ë¡œì»¬ ì²˜ë¦¬ (MediaPipe)", "ì™¸ë¶€ API (Google Cloud Vision)"]
)

slow_motion_factor = st.sidebar.slider(
    "ìŠ¬ë¡œìš° ëª¨ì…˜ ë°°ìœ¨",
    min_value=0.1,
    max_value=1.0,
    value=0.3,
    step=0.1
)

rotation_speed = st.sidebar.slider(
    "ì¹´ë©”ë¼ íšŒì „ ì†ë„",
    min_value=1,
    max_value=10,
    value=3
)

class GolfSwingAnalyzer:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            smooth_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
    def extract_pose_landmarks(self, video_path):
        """ë¹„ë””ì˜¤ì—ì„œ í¬ì¦ˆ ëœë“œë§ˆí¬ ì¶”ì¶œ"""
        cap = cv2.VideoCapture(video_path)
        landmarks_sequence = []
        frames = []
        
        with st.progress(0) as progress_bar:
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            current_frame = 0
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                    
                # RGB ë³€í™˜
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = self.pose.process(frame_rgb)
                
                if results.pose_landmarks:
                    # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ
                    landmarks = []
                    for lm in results.pose_landmarks.landmark:
                        landmarks.append([lm.x, lm.y, lm.z])
                    landmarks_sequence.append(landmarks)
                    frames.append(frame)
                else:
                    landmarks_sequence.append(None)
                    frames.append(frame)
                
                current_frame += 1
                progress_bar.progress(current_frame / frame_count)
        
        cap.release()
        return landmarks_sequence, frames
    
    def detect_golf_swing_phases(self, landmarks_sequence):
        """ê³¨í”„ ìŠ¤ìœ™ ë‹¨ê³„ ìë™ ê°ì§€"""
        if not landmarks_sequence:
            return None, None
        
        # ì†ëª© í¬ì¸íŠ¸ (15: ì™¼ìª½ ì†ëª©, 16: ì˜¤ë¥¸ìª½ ì†ëª©)
        wrist_heights = []
        
        for landmarks in landmarks_sequence:
            if landmarks:
                left_wrist = landmarks[15]
                right_wrist = landmarks[16]
                avg_height = (left_wrist[1] + right_wrist[1]) / 2
                wrist_heights.append(avg_height)
            else:
                wrist_heights.append(None)
        
        # None ê°’ ì œê±° ë° ì¸ë±ìŠ¤ ë§¤í•‘
        valid_heights = [(i, h) for i, h in enumerate(wrist_heights) if h is not None]
        
        if len(valid_heights) < 10:
            return None, None
        
        # Backswing-top íƒì§€ (ìµœê³ ì )
        heights_only = [h for _, h in valid_heights]
        backswing_top_idx = np.argmin(heights_only)  # yê°’ì´ ì‘ì„ìˆ˜ë¡ ë†’ì€ ìœ„ì¹˜
        
        # Address ì‹œì‘ì  (ì²˜ìŒ 10% êµ¬ê°„ì—ì„œ ì•ˆì •ëœ ì§€ì )
        start_region = int(len(valid_heights) * 0.1)
        address_start = 0
        
        # Follow-through ëì  (ë§ˆì§€ë§‰ 20% êµ¬ê°„ì—ì„œ ì•ˆì •ëœ ì§€ì )
        end_region = int(len(valid_heights) * 0.8)
        follow_end = len(valid_heights) - 1
        
        return valid_heights[address_start][0], valid_heights[follow_end][0]
    
    def create_3d_visualization(self, landmarks_sequence, start_frame, end_frame):
        """3D ì‹œê°í™” ë° íšŒì „ ì• ë‹ˆë©”ì´ì…˜ ìƒì„±"""
        if not landmarks_sequence:
            return None
        
        # ìŠ¤ìœ™ êµ¬ê°„ ì¶”ì¶œ
        swing_landmarks = landmarks_sequence[start_frame:end_frame+1]
        
        # 3D í”Œë¡¯ ìƒì„±
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection='3d')
        
        # ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ìƒì„±
        frames_data = []
        
        for frame_idx, landmarks in enumerate(swing_landmarks):
            if landmarks:
                # ì£¼ìš” ê´€ì ˆì ë§Œ ì„ íƒ
                key_points = [0, 1, 2, 5, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]
                x_coords = [landmarks[i][0] for i in key_points]
                y_coords = [landmarks[i][1] for i in key_points]
                z_coords = [landmarks[i][2] for i in key_points]
                
                frames_data.append((x_coords, y_coords, z_coords))
        
        return frames_data
    
    def create_rotating_video(self, frames_data, output_path, rotation_speed=3):
        """íšŒì „í•˜ëŠ” 3D ë¹„ë””ì˜¤ ìƒì„±"""
        if not frames_data:
            return None
        
        temp_dir = tempfile.mkdtemp()
        image_files = []
        
        total_frames = len(frames_data) * 360 // rotation_speed
        
        with st.progress(0) as progress_bar:
            frame_count = 0
            
            for data_idx, (x_coords, y_coords, z_coords) in enumerate(frames_data):
                for angle in range(0, 360, rotation_speed):
                    fig = plt.figure(figsize=(10, 8))
                    ax = fig.add_subplot(111, projection='3d')
                    
                    # 3D ìŠ¤ìºí„° í”Œë¡¯
                    ax.scatter(x_coords, y_coords, z_coords, c='red', s=50)
                    
                    # ì—°ê²°ì„  ê·¸ë¦¬ê¸° (ê°„ë‹¨í•œ ê³¨ê²©)
                    connections = [
                        (0, 1), (1, 2), (2, 5),  # ë¨¸ë¦¬-ì–´ê¹¨
                        (11, 12), (11, 13), (13, 15),  # ì™¼íŒ”
                        (12, 14), (14, 16),  # ì˜¤ë¥¸íŒ”
                        (11, 23), (12, 24),  # ëª¸í†µ
                        (23, 25), (25, 27),  # ì™¼ë‹¤ë¦¬
                        (24, 26), (26, 28)   # ì˜¤ë¥¸ë‹¤ë¦¬
                    ]
                    
                    for start, end in connections:
                        if start < len(x_coords) and end < len(x_coords):
                            ax.plot([x_coords[start], x_coords[end]],
                                   [y_coords[start], y_coords[end]],
                                   [z_coords[start], z_coords[end]], 'b-')
                    
                    # ì¹´ë©”ë¼ ì•µê¸€ ì„¤ì •
                    ax.view_init(elev=20, azim=angle)
                    ax.set_xlim([0, 1])
                    ax.set_ylim([0, 1])
                    ax.set_zlim([-0.5, 0.5])
                    
                    # ì´ë¯¸ì§€ ì €ì¥
                    image_path = os.path.join(temp_dir, f"frame_{frame_count:06d}.png")
                    plt.savefig(image_path, dpi=100, bbox_inches='tight')
                    plt.close()
                    
                    image_files.append(image_path)
                    frame_count += 1
                    progress_bar.progress(frame_count / total_frames)
        
        # ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
        clip = ImageSequenceClip(image_files, fps=24)
        clip.write_videofile(output_path, codec='libx264')
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for file in image_files:
            os.remove(file)
        os.rmdir(temp_dir)
        
        return output_path

class GoogleCloudVisionAPI:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://vision.googleapis.com/v1"
    
    def analyze_video(self, video_bytes):
        """Google Cloud Vision APIë¥¼ í†µí•œ ë¹„ë””ì˜¤ ë¶„ì„"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Google Cloud Video Intelligence API ì‚¬ìš©
        st.warning("ì™¸ë¶€ API ì—°ë™ì€ ë°ëª¨ìš©ì…ë‹ˆë‹¤. ì‹¤ì œ API í‚¤ì™€ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return None

def process_video_local(uploaded_file, slow_motion_factor, rotation_speed):
    """ë¡œì»¬ ì²˜ë¦¬ í•¨ìˆ˜"""
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_path = tmp_file.name
    
    try:
        analyzer = GolfSwingAnalyzer()
        
        st.info("í¬ì¦ˆ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤...")
        landmarks_sequence, frames = analyzer.extract_pose_landmarks(tmp_path)
        
        st.info("ê³¨í”„ ìŠ¤ìœ™ êµ¬ê°„ì„ ê°ì§€ ì¤‘ì…ë‹ˆë‹¤...")
        start_frame, end_frame = analyzer.detect_golf_swing_phases(landmarks_sequence)
        
        if start_frame is None or end_frame is None:
            st.error("ê³¨í”„ ìŠ¤ìœ™ êµ¬ê°„ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        st.success(f"ìŠ¤ìœ™ êµ¬ê°„ ê°ì§€ ì™„ë£Œ: {start_frame} ~ {end_frame} í”„ë ˆì„")
        
        st.info("3D ì‹œê°í™”ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
        frames_data = analyzer.create_3d_visualization(landmarks_sequence, start_frame, end_frame)
        
        st.info("íšŒì „ ë¹„ë””ì˜¤ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
        output_path = tempfile.mktemp(suffix='.mp4')
        result_path = analyzer.create_rotating_video(frames_data, output_path, rotation_speed)
        
        # ìŠ¬ë¡œìš° ëª¨ì…˜ ì ìš©
        if slow_motion_factor < 1.0:
            st.info("ìŠ¬ë¡œìš° ëª¨ì…˜ì„ ì ìš© ì¤‘ì…ë‹ˆë‹¤...")
            clip = VideoFileClip(result_path)
            slow_clip = clip.fx.speedx(slow_motion_factor)
            final_path = tempfile.mktemp(suffix='.mp4')
            slow_clip.write_videofile(final_path, codec='libx264')
            clip.close()
            slow_clip.close()
            os.remove(result_path)
            result_path = final_path
        
        return result_path
        
    finally:
        os.unlink(tmp_path)

def process_video_api(uploaded_file, api_key):
    """ì™¸ë¶€ API ì²˜ë¦¬ í•¨ìˆ˜"""
    if not api_key:
        st.error("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return None
    
    api_client = GoogleCloudVisionAPI(api_key)
    result = api_client.analyze_video(uploaded_file.read())
    return result

# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ“¹ ë¹„ë””ì˜¤ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "ê³¨í”„ ìŠ¤ìœ™ ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['mp4', 'avi', 'mov'],
        help="MP4, AVI, MOV í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤."
    )

with col2:
    st.header("âš™ï¸ ì²˜ë¦¬ ì˜µì…˜")
    
    if processing_mode == "ì™¸ë¶€ API (Google Cloud Vision)":
        api_key = st.text_input(
            "Google Cloud API í‚¤",
            type="password",
            help="Google Cloud Vision API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )

if uploaded_file is not None:
    st.header("ğŸ“Š ê²°ê³¼")
    
    # ì›ë³¸ ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸°
    st.subheader("ì›ë³¸ ë¹„ë””ì˜¤")
    st.video(uploaded_file)
    
    # ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
    if st.button("ğŸš€ 3D ë³€í™˜ ì‹œì‘", type="primary"):
        with st.spinner("ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            if processing_mode == "ë¡œì»¬ ì²˜ë¦¬ (MediaPipe)":
                result_path = process_video_local(
                    uploaded_file, 
                    slow_motion_factor, 
                    rotation_speed
                )
            else:
                result_path = process_video_api(uploaded_file, api_key)
            
            if result_path:
                st.success("ë³€í™˜ ì™„ë£Œ!")
                
                # ê²°ê³¼ ë¹„ë””ì˜¤ í‘œì‹œ
                st.subheader("3D íšŒì „ ê²°ê³¼")
                with open(result_path, 'rb') as video_file:
                    video_bytes = video_file.read()
                    st.video(video_bytes)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.download_button(
                    label="ğŸ“¥ ê²°ê³¼ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
                    data=video_bytes,
                    file_name=f"golf_swing_3d_{uploaded_file.name}",
                    mime="video/mp4"
                )
                
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                os.remove(result_path)
            else:
                st.error("ë¹„ë””ì˜¤ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# ì‚¬ìš©ë²• ì•ˆë‚´
with st.expander("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´"):
    st.markdown("""
    ### ì‚¬ìš© ë‹¨ê³„
    1. **ë¹„ë””ì˜¤ ì—…ë¡œë“œ**: ê³¨í”„ ìŠ¤ìœ™ì´ í¬í•¨ëœ MP4 ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”
    2. **ì²˜ë¦¬ ë°©ì‹ ì„ íƒ**: ë¡œì»¬ ì²˜ë¦¬ ë˜ëŠ” ì™¸ë¶€ API ì¤‘ ì„ íƒí•˜ì„¸ìš”
    3. **ì˜µì…˜ ì„¤ì •**: ìŠ¬ë¡œìš° ëª¨ì…˜ ë°°ìœ¨ê³¼ ì¹´ë©”ë¼ íšŒì „ ì†ë„ë¥¼ ì¡°ì •í•˜ì„¸ìš”
    4. **ë³€í™˜ ì‹œì‘**: '3D ë³€í™˜ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    
    ### íŒ
    - ê³¨í”„ ìŠ¤ìœ™ì´ ëª…í™•íˆ ë³´ì´ëŠ” ê°ë„ì—ì„œ ì´¬ì˜ëœ ì˜ìƒì„ ì‚¬ìš©í•˜ì„¸ìš”
    - ë°°ê²½ì´ ë³µì¡í•˜ì§€ ì•Šì€ í™˜ê²½ì—ì„œ ì´¬ì˜í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - ë¡œì»¬ ì²˜ë¦¬ëŠ” ê°œì¸ì •ë³´ ë³´í˜¸ì— ìœ ë¦¬í•˜ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """)

# ê¸°ìˆ  ì •ë³´
with st.expander("ğŸ”§ ê¸°ìˆ  ì •ë³´"):
    st.markdown("""
    ### ì‚¬ìš©ëœ ê¸°ìˆ 
    - **MediaPipe**: Googleì˜ í¬ì¦ˆ ì¶”ì • ë¼ì´ë¸ŒëŸ¬ë¦¬
    - **OpenCV**: ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ì»´í“¨í„° ë¹„ì „
    - **Matplotlib**: 3D ì‹œê°í™” ë° ì• ë‹ˆë©”ì´ì…˜
    - **MoviePy**: ë¹„ë””ì˜¤ í¸ì§‘ ë° íš¨ê³¼
    - **Streamlit**: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬
    
    ### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
    - M3 ë§¥ ë˜ëŠ” ë™ê¸‰ CPU
    - Python 3.8 ì´ìƒ
    - 8GB ì´ìƒ RAM ê¶Œì¥
    """)
