# file: app.py

import streamlit as st
import tempfile
import os
import cv2
import numpy as np
from PIL import Image
import torch
from moviepy.editor import VideoFileClip, vfx, ImageSequenceClip
from mediapipe.python.solutions import pose as mp_pose


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ìŠ¤ìœ™ êµ¬ê°„ ê°ì§€ (MediaPipe Pose)
def detect_swing_segment(video_path):
    pose = mp_pose.Pose()
    cap = cv2.VideoCapture(video_path)
    start, end = None, None
    fps = cap.get(cv2.CAP_PROP_FPS)
    idx = 0
    swing_detected = False

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        # MediaPipeë¡œ ì™¼ì† ìœ„ì¹˜(or ì˜¤ë¥¸ì†) ì¶”ì í•˜ì—¬ ìŠ¤ìœ™ ì‹œì  ê²€ì¶œ
        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        if results.pose_landmarks:
            wrist = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]
            if wrist.visibility > 0.7:
                if not swing_detected:
                    start = idx
                    swing_detected = True
                end = idx
        idx += 1

    cap.release()
    # ì‹œì‘/ë í”„ë ˆì„ì„ ì´ˆë‹¨ìœ„ë¡œ ë°˜í™˜
    return (start / fps) if start is not None else 0.0, (end / fps) if end is not None else 0.0


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ìŠ¬ë¡œìš°ëª¨ì…˜ ìƒì„± (MoviePy)
def extract_and_slow_motion(video_path, start, end):
    clip = VideoFileClip(video_path).subclip(start, end)
    slowed = clip.fx(vfx.speedx, 0.25)  # 1/4ì†ë„, í•„ìš”í•˜ë©´ 0.3ë¡œë„ ë³€ê²½
    return slowed


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ê¹Šì´ë§µ â†’ í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ë³€í™˜ (ë‹¨ì¼ í”„ë ˆì„ ê¸°ì¤€)
def depth_to_point_cloud(image, depth):
    """
    image: PIL.Image (RGB)
    depth: 2D numpy array (float32), í¬ê¸°ëŠ” imageì™€ ë™ì¼
    """
    h, w = depth.shape
    fx = fy = 1.0
    cx, cy = w / 2.0, h / 2.0

    # (x, y) ì¢Œí‘œ ê·¸ë¦¬ë“œ ìƒì„±
    x, y = np.meshgrid(np.arange(w), np.arange(h))
    z = depth

    # ê° í”½ì…€ì„ 3D ì¢Œí‘œë¡œ ë³€í™˜
    x3 = (x - cx) * z / fx
    y3 = (y - cy) * z / fy
    xyz = np.stack((x3, y3, z), axis=-1).reshape(-1, 3)  # (H*W, 3)

    # ì»¬ëŸ¬ ì •ë³´
    rgb = np.asarray(image).reshape(-1, 3) / 255.0  # (H*W, 3)

    return xyz, rgb


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Z-ë²„í¼ ë Œë”ëŸ¬ë¡œ 360Â° íšŒì „ ì˜ìƒ ìƒì„±
def render_orbit_for_slowclip(slow_clip, save_dir):
    """
    slow_clip: MoviePy VideoFileClip (ìŠ¬ë¡œìš°ëª¨ì…˜ ì „ì²´ êµ¬ê°„)
    save_dir: ì„ì‹œ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    # (a) ìŠ¬ë¡œìš°ëª¨ì…˜ì˜ ê° í”„ë ˆì„ì„ PIL.Imageë¡œ ì¶”ì¶œ
    frames = []
    for frame in slow_clip.iter_frames(fps=15):  # ìŠ¬ë¡œìš° í´ë¦½ FPSë¥¼ 15ë¡œ ê³ ì •
        frames.append(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))
    n_frames = len(frames)

    # (b) ê° í”„ë ˆì„ ë³„ ê¹Šì´ë§µ ìƒì„± (MiDaS)
    st.write(f"ğŸ” ì´ {n_frames} í”„ë ˆì„ì— ëŒ€í•´ ê¹Šì´ë§µ ê³„ì‚° ì¤‘...")
    midas_model = torch.hub.load("intel-isl/MiDaS", "DPT_Large")
    midas_model.eval()
    midas_transform = torch.hub.load("intel-isl/MiDaS", "transforms").dpt_transform

    depth_maps = []
    for img in frames:
        inp = midas_transform(np.array(img)).to("cpu")
        with torch.no_grad():
            pred = midas_model(inp)
            pred = torch.nn.functional.interpolate(
                pred.unsqueeze(1),
                size=img.size[::-1], mode="bicubic", align_corners=False
            ).squeeze().cpu().numpy()
        depth_maps.append(pred)

    # (c) ê° í”„ë ˆì„ë§ˆë‹¤ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„± ë° íšŒì „ ë Œë”ë§
    st.write("ğŸš€ 3D íšŒì „ í•˜ì´ë¼ì´íŠ¸ í”„ë ˆì„ ìƒì„± ì¤‘ (Z-ë²„í¼ ë Œë”ëŸ¬)...")
    all_orbit_frames = []  # ìµœì¢… ì „ì²´ 3D íšŒì „ í”„ë ˆì„ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸

    canvas_size = 256  # ê²°ê³¼ ì˜ìƒ í•´ìƒë„
    num_angles = 60    # ê° í”„ë ˆì„ ë‹¹ 60ì¥ ì‹œì  ìƒì„± (360ë„ / 60 = 6ë„ ë‹¨ìœ„)

    for idx, (img_pil, depth) in enumerate(zip(frames, depth_maps)):
        # (1) ë‹¤ìš´ìƒ˜í”Œ (256Ã—256 ì„±ëŠ¥ í•œê³„ ê³ ë ¤)
        img_small = img_pil.resize((256, 256))
        depth_ds = cv2.resize(depth, (256, 256), interpolation=cv2.INTER_LINEAR)

        # (2) í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        pts, cols = depth_to_point_cloud(img_small, depth_ds)
        center = pts.mean(axis=0)
        pts_centered = pts - center  # ë©”ì‰¬/í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì¤‘ì‹¬ ì •ë ¬

        # (3) ê° ì‹œì ë³„ Z-ë²„í¼ ë Œë”ë§
        #    -> (H*W)ê°œ í¬ì¸íŠ¸ ì´ìš©í•´ 360ë„ orbit
        for angle in np.linspace(0, 2*np.pi, num_angles, endpoint=False):
            # íšŒì „ í–‰ë ¬ (Yì¶• ì£¼ìœ„)
            ca, sa = np.cos(angle), np.sin(angle)
            R = np.array([[ ca, 0, sa],
                          [  0, 1,  0],
                          [-sa, 0, ca]])
            pts_rot = pts_centered.dot(R.T)  # (N,3)

            # ì›ê·¼ íˆ¬ì˜ (ì¹´ë©”ë¼ëŠ” zì¶• ë’¤ìª½ì— ìœ„ì¹˜)
            z_cam = pts_rot[:, 2] + 3.0   # ëª¨ë‘ +3.0 ë°€ì–´ ì¹´ë©”ë¼ ì•ìª½ìœ¼ë¡œ
            eps = 1e-6
            u = (pts_rot[:, 0] / (z_cam + eps) * (canvas_size/2)) + (canvas_size/2)
            v = (pts_rot[:, 1] / (z_cam + eps) * (canvas_size/2)) + (canvas_size/2)
            u = np.round(u).astype(int)
            v = np.round(v).astype(int)

            # Z-ë²„í¼ ì´ˆê¸°í™”
            zbuf = np.full((canvas_size, canvas_size), np.inf)
            cbuf = np.zeros((canvas_size, canvas_size, 3), dtype=np.float32)

            # í¬ì¸íŠ¸ë§ˆë‹¤ Z-ë²„í¼ í…ŒìŠ¤íŠ¸ í›„ ìƒ‰ìƒ ì €ì¥
            for i_pt in range(pts_centered.shape[0]):
                ui, vi, zi = u[i_pt], v[i_pt], z_cam[i_pt]
                if 0 <= ui < canvas_size and 0 <= vi < canvas_size:
                    if zi < zbuf[vi, ui]:
                        zbuf[vi, ui] = zi
                        cbuf[vi, ui, :] = cols[i_pt]

            frame_np = (np.clip(cbuf, 0, 1) * 255).astype(np.uint8)
            all_orbit_frames.append(frame_np)

        st.write(f"  â–¶ Frame {idx+1}/{n_frames} ì²˜ë¦¬ ì™„ë£Œ")

    # (d) ìµœì¢… 3D íšŒì „ í•˜ì´ë¼ì´íŠ¸ ë¹„ë””ì˜¤ ì‘ì„±
    orbit_video_path = os.path.join(tempfile.gettempdir(), "orbit_highlight.mp4")
    ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_RGB2BGR) for f in all_orbit_frames], fps=15).write_videofile(orbit_video_path, codec="libx264")

    return orbit_video_path


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. Streamlit ë©”ì¸ í•¨ìˆ˜
def main():
    st.title("ğŸŒï¸â€â™‚ï¸ ê³¨í”„ ìŠ¤ìœ™ í•˜ì´ë¼ì´íŠ¸ ìƒì„±ê¸° (NumPy Z-ë²„í¼ 3D íšŒì „)")

    uploaded = st.file_uploader("ê³¨í”„ ìŠ¤ìœ™ ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.mp4)", type="mp4")
    if not uploaded:
        st.info("ì™¼ìª½ ìƒë‹¨ì—ì„œ ë™ì˜ìƒì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    # (a) ì—…ë¡œë“œëœ íŒŒì¼ ì„ì‹œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
        tfile.write(uploaded.read())
        video_path = tfile.name

    st.video(video_path)

    # (b) ìŠ¤ìœ™ êµ¬ê°„ ê°ì§€
    st.info("ğŸ” ìŠ¤ìœ™ êµ¬ê°„ ê°ì§€ ì¤‘...")
    start, end = detect_swing_segment(video_path)
    st.success(f"âœ… ìŠ¤ìœ™ êµ¬ê°„: {start:.2f}ì´ˆ ~ {end:.2f}ì´ˆ")

    # (c) ìŠ¬ë¡œìš° ëª¨ì…˜ ìƒì„±
    st.info("ğŸ¢ ìŠ¬ë¡œìš° ëª¨ì…˜ ì˜ìƒ ìƒì„± ì¤‘...")
    slow_clip = extract_and_slow_motion(video_path, start, end)
    slow_path = os.path.join(tempfile.gettempdir(), "slow_motion.mp4")
    slow_clip.write_videofile(slow_path, codec="libx264", audio=False)
    st.video(slow_path)

    # (d) 3D íšŒì „ í•˜ì´ë¼ì´íŠ¸ ìƒì„±
    st.info("ğŸš€ 3D íšŒì „ í•˜ì´ë¼ì´íŠ¸ ë Œë”ë§ ì¤‘... (ìƒí™©ì— ë”°ë¼ ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    orbit_path = render_orbit_for_slowclip(slow_clip, tempfile.gettempdir())
    st.success("ğŸ‰ 3D íšŒì „ í•˜ì´ë¼ì´íŠ¸ ì™„ì„±!")

    st.video(orbit_path)
    with open(orbit_path, "rb") as f:
        st.download_button("ğŸ¬ í•˜ì´ë¼ì´íŠ¸ ì˜ìƒ ë‹¤ìš´ë¡œë“œ", f, file_name="highlight_output.mp4")


if __name__ == "__main__":
    main()
