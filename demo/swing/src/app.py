import streamlit as st
import logging
import logging.handlers
import os
import tempfile
from typing import Dict, Optional, Tuple, List
import uuid
import io
import time

import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import plotly.graph_objects as go
import streamlit as st

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê³¨í”„ ìŠ¤ìœ™ ë¶„ì„ê¸°",
    page_icon="ğŸŒï¸",
    layout="wide"
)

# ë¡œê¹… ì„¤ì •
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

file_handler = logging.handlers.RotatingFileHandler(
    os.path.join(LOG_DIR, "app.log"),
    maxBytes=10*1024*1024,
    backupCount=5
)
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
logging.getLogger().addHandler(file_handler)
logger = logging.getLogger(__name__)

# ì„ì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
TEMP_DIR = os.path.join(tempfile.gettempdir(), "golf_swing_analyzer")
os.makedirs(TEMP_DIR, exist_ok=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'models' not in st.session_state:
    st.session_state.models = None
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False

@st.cache_resource(ttl=None)
def load_models():
    """ëª¨ë¸ ë¡œë“œ ë° ìºì‹±"""
    try:
        import importlib
        import pose_estimation
        import swing_analyzer
        import video_processor
        import analysis_service
        
        # ëª¨ë“ˆ ë¦¬ë¡œë“œ
        importlib.reload(pose_estimation)
        importlib.reload(swing_analyzer)
        importlib.reload(video_processor)
        importlib.reload(analysis_service)
        
        # í´ë˜ìŠ¤ ì„í¬íŠ¸
        from pose_estimation import PoseEstimator
        from swing_analyzer import SwingAnalyzer
        from video_processor import VideoProcessor
        from analysis_service import SwingAnalysisService
        
        logger.debug("Initializing models...")
        pose_estimator = PoseEstimator()
        swing_analyzer = SwingAnalyzer()
        video_processor = VideoProcessor()
        analysis_service = SwingAnalysisService()
        
        # ëª¨ë¸ ì´ˆê¸°í™” í™•ì¸
        logger.debug(f"PoseEstimator methods: {dir(pose_estimator)}")
        logger.debug(f"SwingAnalyzer methods: {dir(swing_analyzer)}")
        logger.debug(f"VideoProcessor methods: {dir(video_processor)}")
        logger.debug(f"AnalysisService methods: {dir(analysis_service)}")
        
        return (
            pose_estimator,
            swing_analyzer,
            video_processor,
            analysis_service
        )
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def get_models() -> Optional[Tuple]:
    """ì„¸ì…˜ì—ì„œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        if st.session_state.models is None:
            logger.debug("Loading models for the first time...")
            st.session_state.models = load_models()
            if st.session_state.models is not None:
                logger.debug("Models loaded successfully")
                pose_estimator, swing_analyzer, video_processor, analysis_service = st.session_state.models
                logger.debug(f"SwingAnalyzer methods after loading: {dir(swing_analyzer)}")
            else:
                logger.error("Failed to load models")
        return st.session_state.models
    except Exception as e:
        logger.error(f"Error in get_models: {str(e)}", exc_info=True)
        return None

def save_uploaded_file(uploaded_file) -> Optional[str]:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì €ì¥í•˜ê³  ê²½ë¡œë¥¼ ë°˜í™˜"""
    try:
        if uploaded_file is None:
            return None
            
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        if file_ext not in ['.mp4', '.avi', '.mov']:
            st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. MP4, AVI, MOV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return None
            
        video_id = f"output_video_{str(uuid.uuid4())[:8]}{file_ext}"
        temp_path = os.path.join(TEMP_DIR, video_id)
        
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getvalue())
            
        return temp_path
    except Exception as e:
        logger.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def analyze_swing(video_path: str, models: Tuple) -> Optional[Dict]:
    """ê³¨í”„ ìŠ¤ìœ™ ë¹„ë””ì˜¤ ë¶„ì„"""
    try:
        if not os.path.exists(video_path):
            st.error("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        if models is None:
            st.error("í•„ìš”í•œ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        pose_estimator, swing_analyzer, _, _ = models

        logger.info(f"Starting analysis for video: {video_path}")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘...")
        
        # SwingAnalyzerì˜ analyze_video ë©”ì„œë“œ ì‚¬ìš© (ì„¸ë¶„í™”ëœ í¬ì¦ˆ ë¶„ì„ í¬í•¨)
        result = swing_analyzer.analyze_video(video_path)
        
        if not result:
            st.error("ë¹„ë””ì˜¤ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None
        
        progress_bar.progress(50)
        status_text.text("ì‹œí€€ìŠ¤ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        
        # ì—°ì† ê²¹ì¹¨ ì‹œí€€ìŠ¤ ìƒì„±
        try:
            continuous_path = os.path.join(TEMP_DIR, "continuous_overlap_sequence.jpg")
            continuous_overlap_path = create_swing_sequence_local(
                video_path, 
                result['key_frames'], 
                continuous_path,
                overlap_mode="continuous"
            )
            if continuous_overlap_path:
                st.session_state.continuous_sequence_path = continuous_overlap_path
                logger.info(f"ì—°ì† ê²¹ì¹¨ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: {continuous_overlap_path}")
        except Exception as e:
            logger.warning(f"ì—°ì† ê²¹ì¹¨ ì‹œí€€ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            st.session_state.continuous_sequence_path = None
        
        progress_bar.progress(100)
        status_text.text("ë¶„ì„ ì™„ë£Œ!")
        
        # UI ì •ë¦¬
        progress_bar.empty()
        status_text.empty()
        
        logger.info(f"ë¶„ì„ ì™„ë£Œ: {len(result.get('frames_data', []))} í”„ë ˆì„ ì²˜ë¦¬ë¨")
        logger.info(f"ê°ì§€ëœ í‚¤ í”„ë ˆì„: {result.get('key_frames', {})}")
        
        return {
            "message": "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "frames": result.get('frames_data', []),
            "frames_data": result.get('frames_data', []),
            "metrics": result.get('metrics', {}),
            "key_frames": result.get('key_frames', {}),
            "evaluations": result.get('evaluations', {})
        }
    except Exception as e:
        logger.error(f"Error in analyze_swing: {str(e)}", exc_info=True)
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def create_sequence_image(video_path: str, key_frames: Dict[str, int], overlap_mode: bool = False, 
                         analysis_frames: List[Dict] = None) -> Optional[np.ndarray]:
    """ìŠ¤ìœ™ ì‹œí€€ìŠ¤ ì´ë¯¸ì§€ ìƒì„± (ì˜¤ë²„ë© ëª¨ë“œ ì§€ì› + ì‚¬ëŒ ì˜ì—­ ìë™ í¬ë¡­)"""
    try:
        if not os.path.exists(video_path):
            st.error("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        frames = []
        frame_order = ['address', 'backswing', 'top', 'impact', 'follow_through']
        
        for phase in frame_order:
            frame_idx = key_frames.get(phase)
            if frame_idx is not None:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                if ret:
                    # ì‚¬ëŒ ì˜ì—­ ìë™ í¬ë¡­ (ëœë“œë§ˆí¬ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
                    if analysis_frames and frame_idx < len(analysis_frames):
                        landmarks_data = analysis_frames[frame_idx]['landmarks']
                        frame = auto_crop_person_area(frame, landmarks_data)
                    
                    # í”„ë ˆì„ í¬ê¸° ì¡°ì •
                    height, width = frame.shape[:2]
                    if width > 800:  # ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆ
                        scale = 800 / width
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        frame = cv2.resize(frame, (new_width, new_height))
                    
                    frames.append((phase, frame))
        
        cap.release()
        
        if not frames:
            st.error("ì‹œí€€ìŠ¤ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        if overlap_mode:
            return create_overlapped_sequence(frames)
        else:
            return create_side_by_side_sequence(frames)
        
    except Exception as e:
        logger.error(f"Error creating sequence image: {str(e)}")
        st.error(f"ì‹œí€€ìŠ¤ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def create_overlapped_sequence(frames: List[Tuple[str, np.ndarray]]) -> np.ndarray:
    """ì˜¤ë²„ë© ë°©ì‹ìœ¼ë¡œ ìŠ¤ìœ™ ì‹œí€€ìŠ¤ ìƒì„±"""
    if not frames:
        raise ValueError("í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê¸°ì¤€ í”„ë ˆì„ (ì²« ë²ˆì§¸ í”„ë ˆì„)
    base_frame = frames[0][1].copy()
    height, width = base_frame.shape[:2]
    
    # ê²°ê³¼ ì´ë¯¸ì§€ ì´ˆê¸°í™” (ì•ŒíŒŒ ì±„ë„ˆë¦¬ í¬í•¨)
    result = np.zeros((height, width, 4), dtype=np.float32)
    
    # ê° í”„ë ˆì„ì„ íˆ¬ëª…ë„ë¥¼ ì¡°ì ˆí•˜ì—¬ ê²¹ì¹˜ê¸°
    alpha_values = [0.8, 0.6, 0.5, 0.4, 0.3]  # ê° ë‹¨ê³„ë³„ íˆ¬ëª…ë„
    colors = [
        (255, 255, 255),  # í°ìƒ‰ (address)
        (255, 200, 100),  # ì—°í•œ ì£¼í™© (backswing)
        (255, 150, 50),   # ì£¼í™© (top)
        (255, 100, 100),  # ì—°í•œ ë¹¨ê°• (impact)
        (200, 100, 255)   # ì—°í•œ ë³´ë¼ (follow_through)
    ]
    
    for i, (phase, frame) in enumerate(frames):
        alpha = alpha_values[i] if i < len(alpha_values) else 0.3
        
        # í”„ë ˆì„ì„ RGBAë¡œ ë³€í™˜
        if len(frame.shape) == 3 and frame.shape[2] == 3:
            frame_rgba = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA).astype(np.float32)
        elif len(frame.shape) == 3 and frame.shape[2] == 4:
            frame_rgba = frame.astype(np.float32)
        else:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì´ë‚˜ ë‹¤ë¥¸ í˜•ì‹ì¸ ê²½ìš° 3ì±„ë„ë¡œ ë³€í™˜
            if len(frame.shape) == 2:
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            frame_rgba = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA).astype(np.float32)
        
        # í¬ê¸°ê°€ ë‹¤ë¥¸ ê²½ìš° ê¸°ì¤€ í”„ë ˆì„ í¬ê¸°ì— ë§ì¶¤
        if frame_rgba.shape[:2] != (height, width):
            frame_rgba = cv2.resize(frame_rgba, (width, height))
        
        # ìƒ‰ìƒ í‹´íŠ¸ ì ìš© (ì„ íƒì‚¬í•­)
        if i > 0:  # ì²« ë²ˆì§¸ í”„ë ˆì„ì€ ì›ë³¸ ìƒ‰ìƒ ìœ ì§€
            tint_color = colors[i] if i < len(colors) else colors[-1]
            frame_rgba[:, :, :3] = frame_rgba[:, :, :3] * 0.7 + np.array(tint_color) * 0.3
        
        # ì•ŒíŒŒ ê°’ ì„¤ì •
        frame_rgba[:, :, 3] = alpha * 255
        
        # ë¸”ë Œë”©
        if i == 0:
            result = frame_rgba.copy()
        else:
            try:
                # ì•ŒíŒŒ ë¸”ë Œë”©
                alpha_norm = frame_rgba[:, :, 3:4] / 255.0
                result[:, :, :3] = result[:, :, :3] * (1 - alpha_norm) + frame_rgba[:, :, :3] * alpha_norm
                result[:, :, 3:4] = np.maximum(result[:, :, 3:4], frame_rgba[:, :, 3:4])
            except Exception as e:
                logger.warning(f"Alpha blending failed: {str(e)}, using simple overlay")
                # ë¸”ë Œë”© ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì˜¤ë²„ë ˆì´
                mask = frame_rgba[:, :, 3] > 0
                result[mask] = frame_rgba[mask]
    
    # BGRë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    result_bgr = cv2.cvtColor(result[:, :, :3].astype(np.uint8), cv2.COLOR_RGB2BGR)
    
    # ë‹¨ê³„ ë¼ë²¨ ì¶”ê°€
    add_phase_labels(result_bgr, frames)
    
    return result_bgr

def create_side_by_side_sequence(frames: List[Tuple[str, np.ndarray]]) -> np.ndarray:
    """ë‚˜ë€íˆ ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ìŠ¤ìœ™ ì‹œí€€ìŠ¤ ìƒì„±"""
    if not frames:
        raise ValueError("í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëª¨ë“  í”„ë ˆì„ì„ ê°™ì€ ë†’ì´ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    target_height = 400
    resized_frames = []
    
    for phase, frame in frames:
        try:
            # í”„ë ˆì„ì´ ìœ íš¨í•œì§€ í™•ì¸
            if frame is None or frame.size == 0:
                logger.warning(f"Invalid frame for phase {phase}")
                continue
                
            # ì±„ë„ ìˆ˜ í™•ì¸ ë° ë³€í™˜
            if len(frame.shape) == 2:
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            elif len(frame.shape) == 3 and frame.shape[2] == 4:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
            elif len(frame.shape) == 3 and frame.shape[2] == 1:
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            
            height, width = frame.shape[:2]
            if height == 0 or width == 0:
                logger.warning(f"Zero dimension frame for phase {phase}")
                continue
                
            scale = target_height / height
            new_width = int(width * scale)
            
            if new_width <= 0:
                logger.warning(f"Invalid new width for phase {phase}")
                continue
                
            resized_frame = cv2.resize(frame, (new_width, target_height))
            resized_frames.append((phase, resized_frame))
            
        except Exception as e:
            logger.error(f"Error resizing frame for phase {phase}: {str(e)}")
            continue
    
    if not resized_frames:
        raise ValueError("ìœ íš¨í•œ ë¦¬ì‚¬ì´ì¦ˆëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì „ì²´ ë„ˆë¹„ ê³„ì‚°
    total_width = sum([frame.shape[1] for _, frame in resized_frames])
    
    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
    result = np.zeros((target_height, total_width, 3), dtype=np.uint8)
    
    # í”„ë ˆì„ë“¤ì„ ë‚˜ë€íˆ ë°°ì¹˜
    x_offset = 0
    for phase, frame in resized_frames:
        try:
            width = frame.shape[1]
            
            # ì•ˆì „í•œ ë²”ìœ„ í™•ì¸
            if x_offset + width <= total_width and frame.shape[0] <= target_height:
                # ì±„ë„ ìˆ˜ í™•ì¸
                if len(frame.shape) == 3 and frame.shape[2] == 3:
                    result[:frame.shape[0], x_offset:x_offset + width] = frame
                else:
                    logger.warning(f"Unexpected frame shape for phase {phase}: {frame.shape}")
                    continue
                    
                # ë‹¨ê³„ ë¼ë²¨ ì¶”ê°€
                cv2.putText(result, phase.upper(), 
                           (x_offset + 10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                x_offset += width
            else:
                logger.warning(f"Frame for phase {phase} exceeds boundaries")
                
        except Exception as e:
            logger.error(f"Error placing frame for phase {phase}: {str(e)}")
            continue
    
    return result

def add_phase_labels(image: np.ndarray, frames: List[Tuple[str, np.ndarray]]) -> None:
    """ì´ë¯¸ì§€ì— ë‹¨ê³„ë³„ ë¼ë²¨ì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
    height, width = image.shape[:2]
    
    # ë¼ë²¨ ìœ„ì¹˜ ê³„ì‚° (ìš°ìƒë‹¨)
    label_x = width - 200
    label_y = 50
    
    # ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    cv2.rectangle(image, (label_x - 10, label_y - 30), 
                 (label_x + 180, label_y + len(frames) * 25), 
                 (0, 0, 0), -1)
    cv2.rectangle(image, (label_x - 10, label_y - 30), 
                 (label_x + 180, label_y + len(frames) * 25), 
                 (255, 255, 255), 2)
    
    # ì œëª© ì¶”ê°€
    cv2.putText(image, "Swing Sequence", 
               (label_x, label_y - 10), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # ê° ë‹¨ê³„ ë¼ë²¨ ì¶”ê°€
    colors = [(255, 255, 255), (100, 200, 255), (50, 150, 255), 
             (100, 100, 255), (255, 100, 255)]
    
    for i, (phase, _) in enumerate(frames):
        color = colors[i] if i < len(colors) else (255, 255, 255)
        cv2.putText(image, f"{i+1}. {phase.replace('_', ' ').title()}", 
                   (label_x, label_y + 20 + i * 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

def create_angle_graph(analysis_data: Dict) -> Optional[bytes]:
    """ê°ë„ ë³€í™” ê·¸ë˜í”„ ìƒì„±"""
    try:
        plt.figure(figsize=(12, 6))
        frames = analysis_data.get('frames', [])
        if not frames:
            st.error("ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        frame_indices = range(len(frames))
        angles = {
            'Right Arm': [frame['angles'].get('right_arm', 0) for frame in frames],
            'Left Arm': [frame['angles'].get('left_arm', 0) for frame in frames],
            'Shoulders': [frame['angles'].get('shoulder_angle', 0) for frame in frames],
            'Hips': [frame['angles'].get('hips_inclination', 0) for frame in frames]
        }
        
        for label, values in angles.items():
            plt.plot(frame_indices, values, label=label)
            
        key_frames = analysis_data.get('key_frames', {})
        for phase, frame_idx in key_frames.items():
            if frame_idx < len(frames):
                plt.axvline(x=frame_idx, color='r', linestyle='--', alpha=0.3)
                plt.text(frame_idx, plt.ylim()[1], phase.upper(), 
                        rotation=45, ha='right')
        
        plt.title('Angle Changes During Swing')
        plt.xlabel('Frame')
        plt.ylabel('Angle (degrees)')
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100)
        plt.close()
        buf.seek(0)
        return buf.getvalue()
        
    except Exception as e:
        logger.error(f"Error creating angle graph: {str(e)}")
        st.error(f"ê°ë„ ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.title("ê³¨í”„ ìŠ¤ìœ™ ë¶„ì„ê¸° ğŸŒï¸")
    st.write("ê³¨í”„ ìŠ¤ìœ™ ì˜ìƒì„ ì—…ë¡œë“œí•˜ì—¬ ìì„¸ë¥¼ ë¶„ì„í•´ë³´ì„¸ìš”!")

    # ëª¨ë¸ ë¡œë“œ
    models = get_models()
    if models is None:
        st.error("í•„ìš”í•œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        return

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'current_tab' not in st.session_state:
        st.session_state.current_tab = 0
    if 'analysis_result' not in st.session_state:
        st.session_state.analysis_result = None
    if 'temp_path' not in st.session_state:
        st.session_state.temp_path = None

    uploaded_file = st.file_uploader("ê³¨í”„ ìŠ¤ìœ™ ì˜ìƒ ì—…ë¡œë“œ", type=['mp4', 'avi', 'mov'])
    
    if uploaded_file is not None:
        temp_path = save_uploaded_file(uploaded_file)
        st.session_state.temp_path = temp_path
        
        if temp_path:
            st.video(temp_path)
            
            if st.button("ìŠ¤ìœ™ ë¶„ì„ ì‹œì‘"):
                with st.spinner("ìŠ¤ìœ™ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    analysis_result = analyze_swing(temp_path, models)
                    
                    if analysis_result:
                        st.session_state.analysis_result = analysis_result
                        st.session_state.analysis_complete = True
                        st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ë¶„ì„ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ íƒ­ í‘œì‹œ
    if st.session_state.get('analysis_complete', False) and st.session_state.analysis_result:
        tab_names = ["ìŠ¤ìœ™ ì‹œí€€ìŠ¤", "ê°ë„ ê·¸ë˜í”„", "3D ë¶„ì„", "ìƒì„¸ ë©”íŠ¸ë¦­ìŠ¤", "ìŠ¤ìœ™ í‰ê°€"]
        tabs = st.tabs(tab_names)

        with tabs[0]:
            show_swing_sequence_with_state(st.session_state.temp_path, st.session_state.analysis_result)
        
        with tabs[1]:
            show_angle_graph(st.session_state.analysis_result)
            
        with tabs[2]:
            show_3d_analysis_with_state(st.session_state.analysis_result)
            
        with tabs[3]:
            show_detailed_metrics(st.session_state.analysis_result)
        
        with tabs[4]:
            show_swing_evaluation(st.session_state.analysis_result)

def show_swing_sequence_with_state(temp_path, analysis_result):
    """ìŠ¤ìœ™ ì‹œí€€ìŠ¤ í‘œì‹œ (ìƒíƒœ ê´€ë¦¬ í¬í•¨)"""
    st.subheader("ìŠ¤ìœ™ ì‹œí€€ìŠ¤")
    
    # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    models = get_models()
    if models is None:
        st.error("ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    _, swing_analyzer, _, _ = models
    
    # í”„ë ˆì„ ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    frames_data = analysis_result.get('frames_data', analysis_result.get('frames', []))
    
    # íƒ­ìœ¼ë¡œ ì„¸ ê°€ì§€ ì‹œí€€ìŠ¤ ë°©ì‹ ë¶„ë¦¬
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ­ ì˜¤ë²„ë© ì‹œí€€ìŠ¤", 
        "ğŸ“‹ ë‚˜ë€íˆ ë°°ì¹˜", 
        "ğŸƒâ€â™‚ï¸ ì—°ì† ê²¹ì¹¨",
        "ğŸ¯ 2D ëª¨ì…˜"
    ])
    
    with tab1:
        st.markdown("### ğŸ­ ì˜¤ë²„ë© ìŠ¤ìœ™ ì‹œí€€ìŠ¤")
        st.markdown("ê° ìŠ¤ìœ™ ë‹¨ê³„ê°€ íˆ¬ëª…ë„ë¥¼ ì¡°ì ˆí•˜ì—¬ ê²¹ì³ì„œ í‘œì‹œë©ë‹ˆë‹¤. ì‚¬ëŒ ì˜ì—­ì„ ìë™ í¬ë¡­í•˜ì—¬ ë”ìš± ì„ ëª…í•˜ê²Œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        try:
            # ì˜¤ë²„ë© ì‹œí€€ìŠ¤ ìƒì„±
            overlap_img = create_sequence_image(
                temp_path, 
                analysis_result['key_frames'], 
                overlap_mode=True, 
                analysis_frames=frames_data
            )
            
            if overlap_img is not None:
                overlap_img_rgb = cv2.cvtColor(overlap_img, cv2.COLOR_BGR2RGB)
                st.image(overlap_img_rgb, use_column_width=True)
                
                # ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                overlap_path = os.path.join(TEMP_DIR, "overlap_sequence.jpg")
                cv2.imwrite(overlap_path, overlap_img)
                
                if os.path.exists(overlap_path):
                    with open(overlap_path, "rb") as file:
                        st.download_button(
                            label="ğŸ’¾ ì˜¤ë²„ë© ì‹œí€€ìŠ¤ ë‹¤ìš´ë¡œë“œ",
                            data=file.read(),
                            file_name="golf_swing_overlap_sequence.jpg",
                            mime="image/jpeg"
                        )
            else:
                st.error("ì˜¤ë²„ë© ì‹œí€€ìŠ¤ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"Error creating overlap sequence: {str(e)}")
            st.error(f"ì˜¤ë²„ë© ì‹œí€€ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    with tab2:
        st.markdown("### ğŸ“‹ ë‚˜ë€íˆ ë°°ì¹˜ ìŠ¤ìœ™ ì‹œí€€ìŠ¤")
        st.markdown("ê° ìŠ¤ìœ™ ë‹¨ê³„ê°€ ìˆœì„œëŒ€ë¡œ ë‚˜ë€íˆ ë°°ì¹˜ë˜ì–´ í‘œì‹œë©ë‹ˆë‹¤. ì‚¬ëŒ ì˜ì—­ì„ ìë™ í¬ë¡­í•˜ì—¬ ê° ë‹¨ê³„ë¥¼ ë”ìš± ëª…í™•í•˜ê²Œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        try:
            # ë‚˜ë€íˆ ë°°ì¹˜ ì‹œí€€ìŠ¤ ìƒì„±
            side_img = create_sequence_image(
                temp_path, 
                analysis_result['key_frames'], 
                overlap_mode=False, 
                analysis_frames=frames_data
            )
            
            if side_img is not None:
                side_img_rgb = cv2.cvtColor(side_img, cv2.COLOR_BGR2RGB)
                st.image(side_img_rgb, use_column_width=True)
                
                # ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                side_path = os.path.join(TEMP_DIR, "side_by_side_sequence.jpg")
                cv2.imwrite(side_path, side_img)
                
                if os.path.exists(side_path):
                    with open(side_path, "rb") as file:
                        st.download_button(
                            label="ğŸ’¾ ë‚˜ë€íˆ ë°°ì¹˜ ì‹œí€€ìŠ¤ ë‹¤ìš´ë¡œë“œ",
                            data=file.read(),
                            file_name="golf_swing_side_by_side_sequence.jpg",
                            mime="image/jpeg"
                        )
            else:
                st.error("ë‚˜ë€íˆ ë°°ì¹˜ ì‹œí€€ìŠ¤ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"Error creating side-by-side sequence: {str(e)}")
            st.error(f"ë‚˜ë€íˆ ë°°ì¹˜ ì‹œí€€ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    with tab3:
        st.markdown("### ğŸƒâ€â™‚ï¸ ì—°ì† ê²¹ì¹¨ ì‹œí€€ìŠ¤")
        st.markdown("**30% ê²¹ì¹¨ìœ¼ë¡œ ì—°ì†ì ì¸ ìŠ¤ìœ™ ëª¨ì…˜ì„ ë³´ì—¬ì£¼ëŠ” ì‹œí€€ìŠ¤**")
        
        if 'continuous_sequence_path' in st.session_state and st.session_state.continuous_sequence_path:
          st.image(st.session_state.continuous_sequence_path, caption="ì—°ì† ê²¹ì¹¨ ì‹œí€€ìŠ¤")
          
          # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
          if os.path.exists(st.session_state.continuous_sequence_path):
            with open(st.session_state.continuous_sequence_path, "rb") as file:
              st.download_button(
                label="ğŸ“¥ ì—°ì† ê²¹ì¹¨ ì‹œí€€ìŠ¤ ë‹¤ìš´ë¡œë“œ",
                data=file.read(),
                file_name="continuous_overlap_sequence.jpg",
                mime="image/jpeg"
              )
        else:
          st.info("ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì™„ë£Œí•˜ë©´ ì—°ì† ê²¹ì¹¨ ì‹œí€€ìŠ¤ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

    with tab4:
        st.markdown("### ğŸ¯ 2D ëª¨ì…˜ ì‹œê°í™”")
        st.markdown("**í”„ë ˆì„ë³„ 2D í¬ì¦ˆë¥¼ ì‹œê°í™”í•˜ê³  ìŠ¤ìœ™ ëª¨ì…˜ì„ ë¶„ì„í•©ë‹ˆë‹¤.**")
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'motion_2d_frame_idx' not in st.session_state:
            st.session_state.motion_2d_frame_idx = 0
        if 'motion_2d_is_playing' not in st.session_state:
            st.session_state.motion_2d_is_playing = False
        
        # í”„ë ˆì„ ë°ì´í„° í™•ì¸
        if not frames_data:
            st.warning("ë¶„ì„ëœ í”„ë ˆì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
        if st.session_state.motion_2d_frame_idx >= len(frames_data):
            st.session_state.motion_2d_frame_idx = len(frames_data) - 1
        
        # ì»¨íŠ¸ë¡¤ ì„¹ì…˜
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # í”„ë ˆì„ ìŠ¬ë¼ì´ë”
            st.session_state.motion_2d_frame_idx = st.slider(
                "í”„ë ˆì„ ì„ íƒ", 
                0, 
                len(frames_data) - 1, 
                st.session_state.motion_2d_frame_idx,
                key="motion_2d_slider"
            )
            
            # ì¬ìƒ ì»¨íŠ¸ë¡¤
            cols = st.columns(4)
            if cols[0].button("â®ï¸ ì²˜ìŒìœ¼ë¡œ", key="motion_2d_first"):
                st.session_state.motion_2d_frame_idx = 0
                st.session_state.motion_2d_is_playing = False
            if cols[1].button("â–¶ï¸ ì¬ìƒ" if not st.session_state.motion_2d_is_playing else "â¸ï¸ ì¼ì‹œì •ì§€", key="motion_2d_play"):
                st.session_state.motion_2d_is_playing = not st.session_state.motion_2d_is_playing
            if cols[2].button("â­ï¸ ëìœ¼ë¡œ", key="motion_2d_last"):
                st.session_state.motion_2d_frame_idx = len(frames_data) - 1
                st.session_state.motion_2d_is_playing = False
            if cols[3].button("ğŸ”„ ë¦¬ì…‹", key="motion_2d_reset"):
                st.session_state.motion_2d_frame_idx = 0
                st.session_state.motion_2d_is_playing = False
        
        with col2:
            # í˜„ì¬ í”„ë ˆì„ ì •ë³´
            current_frame_data = frames_data[st.session_state.motion_2d_frame_idx]
            st.markdown("### í˜„ì¬ í”„ë ˆì„ ì •ë³´")
            st.metric("í”„ë ˆì„ ë²ˆí˜¸", st.session_state.motion_2d_frame_idx)
            
            # ì£¼ìš” ê°ë„ í‘œì‹œ
            angles = current_frame_data.get('angles', {})
            if angles:
                st.metric("ì–´ê¹¨ íšŒì „", f"{angles.get('shoulder_angle', 0):.1f}Â°")
                st.metric("ì˜¤ë¥¸íŒ” ê°ë„", f"{angles.get('right_arm', 0):.1f}Â°")
                st.metric("ì™¼íŒ” ê°ë„", f"{angles.get('left_arm', 0):.1f}Â°")
        
        # 2D í¬ì¦ˆ ì‹œê°í™”
        st.markdown("### 2D í¬ì¦ˆ ì‹œê°í™”")
        try:
            # Plotlyë¥¼ ì‚¬ìš©í•œ 2D í¬ì¦ˆ ì‹œê°í™”
            fig = create_pose_visualization(current_frame_data)
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.error(f"2D í¬ì¦ˆ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # í‚¤ í”„ë ˆì„ í‘œì‹œ
        key_frames = analysis_result.get('key_frames', {})
        if key_frames:
            st.markdown("### ì£¼ìš” í”„ë ˆì„")
            for phase, frame_idx in key_frames.items():
                if frame_idx == st.session_state.motion_2d_frame_idx:
                    st.success(f"í˜„ì¬ í”„ë ˆì„ì€ '{phase}' ë‹¨ê³„ì…ë‹ˆë‹¤.")
        
        # ìë™ ì¬ìƒ ë¡œì§
        if st.session_state.motion_2d_is_playing:
            if st.session_state.motion_2d_frame_idx < len(frames_data) - 1:
                st.session_state.motion_2d_frame_idx += 1
                time.sleep(0.1)  # í”„ë ˆì„ ê°„ ë”œë ˆì´
                st.rerun()
            else:
                st.session_state.motion_2d_is_playing = False
                st.rerun()

def show_3d_analysis_with_state(analysis_result):
    """3D ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ìƒíƒœ ê´€ë¦¬ í¬í•¨)"""
    st.subheader("3D ìŠ¤ìœ™ ë¶„ì„")
    
    # í”„ë ˆì„ ë°ì´í„° í‚¤ ì¼ì¹˜ì„± í™•ì¸
    frames_data = analysis_result.get('frames_data', analysis_result.get('frames', []))
    if not frames_data:
        st.error("ë¶„ì„ëœ í”„ë ˆì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'three_d_frame_idx' not in st.session_state:
        st.session_state.three_d_frame_idx = 0
    if 'three_d_is_playing' not in st.session_state:
        st.session_state.three_d_is_playing = False
    
    # ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸ ë° ìˆ˜ì •
    if st.session_state.three_d_frame_idx >= len(frames_data):
        st.session_state.three_d_frame_idx = len(frames_data) - 1
    
    # 3D í¬ì¦ˆ ì‹œê°í™”
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("3D í¬ì¦ˆ ë·°ì–´")
        
        # ì„¸ë¶€ ìˆ˜ì¤€ ì„ íƒ
        detail_level = st.selectbox(
            "ğŸ¨ ì„¸ë¶€ ìˆ˜ì¤€ ì„ íƒ",
            options=['basic', 'medium', 'full'],
            index=2,  # ê¸°ë³¸ê°’: full
            help="basic: ê¸°ë³¸ ê³¨ê²©ë§Œ, medium: ì†ë°œ ì¶”ê°€, full: ëª¨ë“  ì„¸ë¶€ì‚¬í•­"
        )
        
        # ì„¸ë¶€ ìˆ˜ì¤€ ì„¤ëª…
        if detail_level == 'basic':
            st.info("ğŸ’¡ ê¸°ë³¸ ê³¨ê²©: ì–´ê¹¨, íŒ”, ëª¸í†µ, ë‹¤ë¦¬ì˜ ì£¼ìš” ë¼ˆëŒ€ë§Œ í‘œì‹œ")
        elif detail_level == 'medium':
            st.info("ğŸ’¡ ì¤‘ê°„ ì„¸ë¶€: ê¸°ë³¸ ê³¨ê²© + ì†ê³¼ ë°œì˜ ì„¸ë¶€ êµ¬ì¡° í‘œì‹œ")
        else:
            st.info("ğŸ’¡ ëª¨ë“  ì„¸ë¶€ì‚¬í•­: ì–¼êµ´, ì†, ë°œì„ í¬í•¨í•œ 33ê°œ ëª¨ë“  í¬ì¸íŠ¸ì™€ ë¶€ë“œëŸ¬ìš´ ê³¡ì„  í‘œì‹œ")
        
        # ê¶¤ì  í‘œì‹œ ì˜µì…˜
        show_trajectory = st.checkbox("ğŸŒï¸ ìŠ¤ìœ™ ê¶¤ì  í‘œì‹œ", value=False, help="í´ëŸ½(ì†ëª©)ì˜ ìŠ¤ìœ™ ê¶¤ì ì„ í‘œì‹œí•©ë‹ˆë‹¤")
        
        st.session_state.three_d_frame_idx = st.slider(
            "í”„ë ˆì„ ì„ íƒ", 
            0, 
            len(frames_data) - 1, 
            st.session_state.three_d_frame_idx,
            key="3d_frame_slider"
        )
        
        # Plotlyë¥¼ ì‚¬ìš©í•œ 3D ì‹œê°í™”
        current_frame = frames_data[st.session_state.three_d_frame_idx]
        trajectory_data = frames_data if show_trajectory else None
        fig = create_3d_pose_plot(current_frame, detail_level, show_trajectory, trajectory_data)
        st.plotly_chart(fig, use_container_width=True)
        
        # ì¬ìƒ ì»¨íŠ¸ë¡¤
        cols = st.columns(3)
        if cols[0].button("â®ï¸ ì²˜ìŒìœ¼ë¡œ", key="3d_first"):
            st.session_state.three_d_frame_idx = 0
            st.session_state.three_d_is_playing = False
        if cols[1].button("â–¶ï¸ ì¬ìƒ" if not st.session_state.three_d_is_playing else "â¸ï¸ ì¼ì‹œì •ì§€", key="3d_play"):
            st.session_state.three_d_is_playing = not st.session_state.three_d_is_playing
        if cols[2].button("â­ï¸ ëìœ¼ë¡œ", key="3d_last"):
            st.session_state.three_d_frame_idx = len(frames_data) - 1
            st.session_state.three_d_is_playing = False
    
    with col2:
        st.subheader("3D ë©”íŠ¸ë¦­ìŠ¤")
        show_3d_metrics(analysis_result, st.session_state.three_d_frame_idx)
    
    # ìë™ ì¬ìƒ ë¡œì§
    if st.session_state.three_d_is_playing:
        if st.session_state.three_d_frame_idx < len(frames_data) - 1:
            st.session_state.three_d_frame_idx += 1
            time.sleep(0.1)  # í”„ë ˆì„ ê°„ ë”œë ˆì´
            st.rerun()
        else:
            st.session_state.three_d_is_playing = False
            st.rerun()

def create_pose_visualization(frame_data: Dict) -> go.Figure:
    """í”„ë ˆì„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 2D í¬ì¦ˆ ì‹œê°í™” ìƒì„± - ê°œì„ ëœ ë²„ì „ (ë” ë§ì€ ì , ê²€ì€ ë°°ê²½)"""
    # Plotly í”¼ê²¨ ìƒì„±
    fig = go.Figure()
    
    # í™•ì¥ëœ ëœë“œë§ˆí¬ ì—°ê²° ì •ì˜ (ë” ë§ì€ ì—°ê²°ì„ )
    basic_connections = [
        ('left_shoulder', 'right_shoulder'),
        ('left_shoulder', 'left_elbow'),
        ('left_elbow', 'left_wrist'),
        ('right_shoulder', 'right_elbow'),
        ('right_elbow', 'right_wrist'),
        ('left_shoulder', 'left_hip'),
        ('right_shoulder', 'right_hip'),
        ('left_hip', 'right_hip'),
        ('left_hip', 'left_knee'),
        ('left_knee', 'left_ankle'),
        ('right_hip', 'right_knee'),
        ('right_knee', 'right_ankle')
    ]
    
    # ì–¼êµ´ ì—°ê²° (ìˆëŠ” ê²½ìš°)
    face_connections = [
        ('nose', 'left_eye'), ('nose', 'right_eye'),
        ('left_eye', 'left_ear'), ('right_eye', 'right_ear'),
        ('mouth_left', 'mouth_right')
    ]
    
    # ì† ì—°ê²° (ìˆëŠ” ê²½ìš°)
    hand_connections = [
        ('left_wrist', 'left_pinky'), ('left_wrist', 'left_index'), ('left_wrist', 'left_thumb'),
        ('right_wrist', 'right_pinky'), ('right_wrist', 'right_index'), ('right_wrist', 'right_thumb')
    ]
    
    # ë°œ ì—°ê²° (ìˆëŠ” ê²½ìš°)
    foot_connections = [
        ('left_ankle', 'left_heel'), ('left_heel', 'left_foot_index'),
        ('right_ankle', 'right_heel'), ('right_heel', 'right_foot_index')
    ]
    
    landmarks = frame_data['landmarks']
    
    # ëª¨ë“  ëœë“œë§ˆí¬ ì  ì¶”ê°€ (ìƒ‰ìƒë³„ë¡œ êµ¬ë¶„)
    for name, point in landmarks.items():
        # í¬ì¸íŠ¸ íƒ€ì…ì— ë”°ë¼ ìƒ‰ìƒê³¼ í¬ê¸° êµ¬ë¶„
        if 'eye' in name or 'ear' in name or 'nose' in name or 'mouth' in name:
            color = '#FFD700'  # ê³¨ë“œ (ì–¼êµ´)
            size = 8
        elif 'wrist' in name or 'pinky' in name or 'index' in name or 'thumb' in name:
            color = '#FF69B4'  # í•« í•‘í¬ (ì†)
            size = 10
        elif 'ankle' in name or 'heel' in name or 'foot' in name:
            color = '#00FF7F'  # ìŠ¤í”„ë§ ê·¸ë¦° (ë°œ)
            size = 10
        else:
            color = '#FFFFFF'  # í°ìƒ‰ (ê¸°ë³¸ ê³¨ê²©)
            size = 12
        
        fig.add_trace(go.Scatter(
            x=[point[0]], 
            y=[point[1]],
            mode='markers+text',
            name=name,
            text=[name],
            textposition='top center',
            marker=dict(
                size=size, 
                color=color,
                line=dict(color='black', width=1)  # í…Œë‘ë¦¬ ì¶”ê°€
            ),
            textfont=dict(
                size=8,
                color='white'  # í…ìŠ¤íŠ¸ë¥¼ í°ìƒ‰ìœ¼ë¡œ
            ),
            showlegend=False,
            hovertemplate=f'<b>{name}</b><br>x: %{{x:.3f}}<br>y: %{{y:.3f}}<extra></extra>'
        ))
    
    # ì—°ê²°ì„  ì¶”ê°€ í•¨ìˆ˜
    def add_connections(connections, color, width=3):
        for start, end in connections:
            if start in landmarks and end in landmarks:
                start_point = landmarks[start]
                end_point = landmarks[end]
                fig.add_trace(go.Scatter(
                    x=[start_point[0], end_point[0]],
                    y=[start_point[1], end_point[1]],
                    mode='lines',
                    line=dict(width=width, color=color),
                    showlegend=False,
                    hoverinfo='skip'
                ))
    
    # ê° ë¶€ìœ„ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒì˜ ì—°ê²°ì„  ì¶”ê°€
    add_connections(basic_connections, '#00D4FF', 4)      # ì‹œì•„ë…¸ ë¸”ë£¨ (ê¸°ë³¸ ê³¨ê²©)
    add_connections(face_connections, '#FFB347', 2)       # í”¼ì¹˜ (ì–¼êµ´)
    add_connections(hand_connections, '#DA70D6', 2)       # ì˜¤í‚¤ë“œ (ì†)
    add_connections(foot_connections, '#32CD32', 3)       # ë¼ì„ ê·¸ë¦° (ë°œ)
    
    # ë°ì´í„° ë²”ìœ„ ê³„ì‚° (ì˜¤í†  ìŠ¤ì¼€ì¼ì„ ìœ„í•´)
    x_coords = [point[0] for point in landmarks.values()]
    y_coords = [point[1] for point in landmarks.values()]
    
    # ì—¬ë°±ì„ ìœ„í•œ íŒ¨ë”© ê³„ì‚°
    x_range = max(x_coords) - min(x_coords)
    y_range = max(y_coords) - min(y_coords)
    padding = max(x_range, y_range) * 0.1  # 10% íŒ¨ë”©
    
    x_min, x_max = min(x_coords) - padding, max(x_coords) + padding
    y_min, y_max = min(y_coords) - padding, max(y_coords) + padding
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì • (ê²€ì€ ë°°ê²½, ì˜¤í†  ìŠ¤ì¼€ì¼)
    fig.update_layout(
        showlegend=False,
        xaxis=dict(
            title='X (ì¢Œìš°)',
            showgrid=True,
            gridcolor='rgba(128, 128, 128, 0.3)',  # íšŒìƒ‰ ë°˜íˆ¬ëª… ê·¸ë¦¬ë“œ
            color='white',
            zeroline=False,
            range=[x_min, x_max]  # ë°ì´í„°ì— ë§ì¶˜ ë²”ìœ„
        ),
        yaxis=dict(
            title='Y (ìƒí•˜)',
            showgrid=True,
            gridcolor='rgba(128, 128, 128, 0.3)',  # íšŒìƒ‰ ë°˜íˆ¬ëª… ê·¸ë¦¬ë“œ
            color='white',
            zeroline=False,
            range=[y_max, y_min],  # yì¶• ë°˜ì „ (ìœ„ìª½ì´ 0ì— ê°€ê¹ê²Œ)
            scaleanchor="x",
            scaleratio=1
        ),
        margin=dict(l=50, r=50, t=50, b=50),
        plot_bgcolor='black',      # í”Œë¡¯ ë°°ê²½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ
        paper_bgcolor='black',     # ì „ì²´ ë°°ê²½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ
        font=dict(color='white'),  # í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ í°ìƒ‰ìœ¼ë¡œ
        width=600,
        height=600
    )
    
    return fig

def create_3d_pose_plot(frame_data: Dict, detail_level: str = 'full', 
                       show_trajectory: bool = False, trajectory_data: Optional[List[Dict]] = None) -> go.Figure:
    """í”„ë ˆì„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 3D í¬ì¦ˆ í”Œë¡¯ ìƒì„± - ê°œì„ ëœ ë²„ì „"""
    try:
        # 3D ì‹œê°í™” í´ë˜ìŠ¤ ì‚¬ìš©
        from visualization_3d import SwingVisualizer3D
        visualizer = SwingVisualizer3D()
        
        # ì„¸ë¶€ ìˆ˜ì¤€ì— ë”°ë¼ 3D í”Œë¡¯ ìƒì„±
        fig = visualizer.create_pose_plot(frame_data, show_trajectory=show_trajectory, 
                                        trajectory_data=trajectory_data, detail_level=detail_level)
        
        # ì¢Œí‘œì¶•ê³¼ ê·¸ë¦¬ë“œ ì¶”ê°€
        axis_length = 0.5
        origin = [0, 0, 0]
        
        # Xì¶• (ë¹¨ê°„ìƒ‰) - ì¢Œìš°
        fig.add_trace(go.Scatter3d(
            x=[origin[0], origin[0] + axis_length],
            y=[origin[1], origin[1]],
            z=[origin[2], origin[2]],
            mode='lines+text',
            line=dict(color='red', width=3),
            text=['', 'X'],
            showlegend=False
        ))
        
        # Yì¶• (ì´ˆë¡ìƒ‰) - ìƒí•˜
        fig.add_trace(go.Scatter3d(
            x=[origin[0], origin[0]],
            y=[origin[1], origin[1] + axis_length],
            z=[origin[2], origin[2]],
            mode='lines+text',
            line=dict(color='green', width=3),
            text=['', 'Y'],
            showlegend=False
        ))
        
        # Zì¶• (íŒŒë€ìƒ‰) - ì•ë’¤
        fig.add_trace(go.Scatter3d(
            x=[origin[0], origin[0]],
            y=[origin[1], origin[1]],
            z=[origin[2], origin[2] + axis_length],
            mode='lines+text',
            line=dict(color='blue', width=3),
            text=['', 'Z'],
            showlegend=False
        ))
        
        # ë°”ë‹¥ ê·¸ë¦¬ë“œ ì¶”ê°€ (X-Z í‰ë©´)
        grid_size = 1.0
        grid_points = np.linspace(-grid_size/2, grid_size/2, 10)
        for x in grid_points:
            fig.add_trace(go.Scatter3d(
                x=[x, x],
                y=[0, 0],
                z=[-grid_size/2, grid_size/2],
                mode='lines',
                line=dict(color='gray', width=1),
                showlegend=False
            ))
        for z in grid_points:
            fig.add_trace(go.Scatter3d(
                x=[-grid_size/2, grid_size/2],
                y=[0, 0],
                z=[z, z],
                mode='lines',
                line=dict(color='gray', width=1),
                showlegend=False
            ))
        
        # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸ (í¬ê¸° ì¡°ì •)
        fig.update_layout(
            width=800,
            height=600
        )
        
        return fig
        
    except Exception as e:
        logger.error(f"Error creating 3D pose plot: {str(e)}")
        return go.Figure()

def show_3d_metrics(analysis_result, frame_idx):
    """3D ë©”íŠ¸ë¦­ìŠ¤ í‘œì‹œ"""
    frame_data = analysis_result['frames'][frame_idx]
    
    # í˜„ì¬ í”„ë ˆì„ì˜ 3D ê°ë„ ê³„ì‚°
    angles_3d = calculate_3d_angles(frame_data['landmarks'])
    
    # ë©”íŠ¸ë¦­ìŠ¤ í‘œì‹œ
    st.metric("ì²™ì¶” ê°ë„", f"{angles_3d['spine_angle']:.1f}Â°")
    st.metric("ì–´ê¹¨ íšŒì „", f"{angles_3d['shoulder_rotation']:.1f}Â°")
    st.metric("í™ íšŒì „", f"{angles_3d['hip_rotation']:.1f}Â°")
    st.metric("íŒ” ê°ë„ (ì˜¤ë¥¸ìª½)", f"{angles_3d['right_arm_angle']:.1f}Â°")
    st.metric("ë¬´ë¦ ê°ë„ (ì˜¤ë¥¸ìª½)", f"{angles_3d['right_knee_angle']:.1f}Â°")

def calculate_3d_angles(landmarks):
    """3D ê°ë„ ê³„ì‚°"""
    import numpy as np
    
    def calculate_angle(p1, p2, p3):
        """ì„¸ ì  ì‚¬ì´ì˜ 3D ê°ë„ ê³„ì‚°"""
        v1 = np.array(p1) - np.array(p2)
        v2 = np.array(p3) - np.array(p2)
        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
        return np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))
    
    # ì²™ì¶” ê°ë„
    hip_center = np.mean([landmarks['left_hip'], landmarks['right_hip']], axis=0)
    shoulder_center = np.mean([landmarks['left_shoulder'], landmarks['right_shoulder']], axis=0)
    vertical = hip_center + np.array([0, 1, 0])
    spine_angle = calculate_angle(vertical, hip_center, shoulder_center)
    
    # ì–´ê¹¨ íšŒì „
    shoulder_vector = np.array(landmarks['right_shoulder']) - np.array(landmarks['left_shoulder'])
    forward = np.array([0, 0, 1])
    shoulder_rotation = np.degrees(np.arctan2(shoulder_vector[0], shoulder_vector[2]))
    
    # í™ íšŒì „
    hip_vector = np.array(landmarks['right_hip']) - np.array(landmarks['left_hip'])
    hip_rotation = np.degrees(np.arctan2(hip_vector[0], hip_vector[2]))
    
    # ì˜¤ë¥¸íŒ” ê°ë„
    right_arm_angle = calculate_angle(
        landmarks['right_shoulder'],
        landmarks['right_elbow'],
        landmarks['right_wrist']
    )
    
    # ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„
    right_knee_angle = calculate_angle(
        landmarks['right_hip'],
        landmarks['right_knee'],
        landmarks['right_ankle']
    )
    
    return {
        'spine_angle': spine_angle,
        'shoulder_rotation': shoulder_rotation,
        'hip_rotation': hip_rotation,
        'right_arm_angle': right_arm_angle,
        'right_knee_angle': right_knee_angle
    }

def show_angle_graph(analysis_result):
    """ê°ë„ ê·¸ë˜í”„ í‘œì‹œ"""
    st.subheader("ê°ë„ ë³€í™” ê·¸ë˜í”„")
    graph_bytes = create_angle_graph(analysis_result)
    if graph_bytes:
        st.image(graph_bytes)
        
        # ê·¸ë˜í”„ í•´ì„ ì¶”ê°€
        st.markdown("### ğŸ“Š ê·¸ë˜í”„ í•´ì„")
        metrics = analysis_result.get('metrics', {})
        
        st.markdown("""
        #### ì£¼ìš” ì§€í‘œ ì„¤ëª…:
        - **ì–´ê¹¨ íšŒì „ (Shoulders)**: ë°±ìŠ¤ìœ™ì—ì„œ ì–´ê¹¨ì˜ íšŒì „ ê°ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ìƒì ì¸ ìµœëŒ€ íšŒì „ì€ 80ë„ ì´ìƒì…ë‹ˆë‹¤.
        - **íŒ” ê°ë„ (Right/Left Arm)**: íŒ”ì˜ í´ì§ ì •ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì–´ë“œë ˆìŠ¤ì™€ ì„íŒ©íŠ¸ì—ì„œ 165-180ë„ê°€ ì´ìƒì ì…ë‹ˆë‹¤.
        - **í™ íšŒì „ (Hips)**: ê³¨ë°˜ì˜ íšŒì „ ê°ë„ì…ë‹ˆë‹¤. ì„íŒ©íŠ¸ ì‹œì ì—ì„œ 45ë„ ì´ìƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.
        """)
        
        # í˜„ì¬ ìŠ¤ìœ™ì˜ íŠ¹ì§• ë¶„ì„
        st.markdown("#### ğŸ¯ í˜„ì¬ ìŠ¤ìœ™ ë¶„ì„")
        shoulder_rotation = metrics.get('shoulder_rotation', 0)
        impact_angle = metrics.get('impact_angle', 0)
        hip_rotation = metrics.get('hip_rotation', 0)
        
        analysis_text = []
        if shoulder_rotation >= 80:
            analysis_text.append("âœ… ì–´ê¹¨ íšŒì „ì´ ì¶©ë¶„í•©ë‹ˆë‹¤ ({}ë„)".format(round(shoulder_rotation, 1)))
        else:
            analysis_text.append("âŒ ì–´ê¹¨ íšŒì „ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({}ë„, ëª©í‘œ: 80ë„ ì´ìƒ)".format(round(shoulder_rotation, 1)))
            
        if 165 <= impact_angle <= 180:
            analysis_text.append("âœ… ì„íŒ©íŠ¸ ì‹œ íŒ” ê°ë„ê°€ ì´ìƒì ì…ë‹ˆë‹¤ ({}ë„)".format(round(impact_angle, 1)))
        else:
            analysis_text.append("âŒ ì„íŒ©íŠ¸ ì‹œ íŒ” ê°ë„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤ ({}ë„, ëª©í‘œ: 165-180ë„)".format(round(impact_angle, 1)))
            
        if hip_rotation >= 45:
            analysis_text.append("âœ… í™ íšŒì „ì´ ì¶©ë¶„í•©ë‹ˆë‹¤ ({}ë„)".format(round(hip_rotation, 1)))
        else:
            analysis_text.append("âŒ í™ íšŒì „ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({}ë„, ëª©í‘œ: 45ë„ ì´ìƒ)".format(round(hip_rotation, 1)))
        
        for text in analysis_text:
            st.markdown(text)

def show_detailed_metrics(analysis_result):
    """ìƒì„¸ ë©”íŠ¸ë¦­ìŠ¤ í‘œì‹œ"""
    st.subheader("ìƒì„¸ ë©”íŠ¸ë¦­ìŠ¤")
    metrics = analysis_result['metrics']
    cols = st.columns(3)
    for idx, (metric_name, value) in enumerate(metrics.items()):
        with cols[idx % 3]:
            st.metric(
                label=metric_name,
                value=f"{value:.2f}Â°" if isinstance(value, (int, float)) else value
            )

def show_swing_evaluation(analysis_result):
    """ìŠ¤ìœ™ í‰ê°€ í‘œì‹œ"""
    st.subheader("ìŠ¤ìœ™ í‰ê°€")
    
    # í‰ê°€ ê¸°ì¤€ í‘œ ìƒì„±
    st.markdown("### âš–ï¸ í‰ê°€ ê¸°ì¤€")
    
    criteria_data = {
        "ìŠ¤ìœ™ ë‹¨ê³„": ["ì–´ë“œë ˆìŠ¤ ìì„¸", "ì–´ë“œë ˆìŠ¤ ìì„¸", 
                    "íƒ‘ ìì„¸", "íƒ‘ ìì„¸",
                    "ì„íŒ©íŠ¸ ìì„¸", "ì„íŒ©íŠ¸ ìì„¸",
                    "íŒ”ë¡œìš° ìŠ¤ë£¨", "íŒ”ë¡œìš° ìŠ¤ë£¨",
                    "í”¼ë‹ˆì‹œ ìì„¸", "í”¼ë‹ˆì‹œ ìì„¸"],
        "í‰ê°€ í•­ëª©": ["íŒ” ê°ë„", "ìì„¸ ì•ˆì •ì„±",
                    "ì–´ê¹¨ íšŒì „", "ë¨¸ë¦¬ ì•ˆì •ì„±",
                    "íŒ” ê°ë„", "í™ íšŒì „",
                    "íŒ”ë¡œìš° ìŠ¤ë£¨ ì™„ì„±ë„", "ê· í˜•",
                    "ë§ˆë¬´ë¦¬ ë™ì‘", "ê· í˜•"],
        "ê¸°ì¤€ê°’": ["165-180ë„", "ì²™ì¶” ê°ë„ 30ë„ ì´ìƒ",
                 "ìµœì†Œ 80ë„ ì´ìƒ", "ì´ˆê¸° ìœ„ì¹˜ì—ì„œ ì›€ì§ì„ 0.1 ì´í•˜",
                 "165-180ë„", "45ë„ ì´ìƒ",
                 "íŒ” ê°ë„ 120ë„ ì´í•˜", "ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„ 160ë„ ì´í•˜",
                 "íŒ” ê°ë„ 120ë„ ì´í•˜", "ì˜¤ë¥¸ìª½ ë¬´ë¦ ê°ë„ 160ë„ ì´í•˜"],
        "ì¤‘ìš”ë„": ["â­â­â­", "â­â­",
                 "â­â­â­", "â­â­",
                 "â­â­â­", "â­â­â­",
                 "â­â­", "â­â­",
                 "â­â­", "â­â­"]
    }
    
    import pandas as pd
    criteria_df = pd.DataFrame(criteria_data)
    
    # í‘œ ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ CSS
    st.markdown("""
    <style>
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th {
        background-color: #1E1E1E;
        color: white;
        text-align: center !important;
    }
    td {
        text-align: center !important;
    }
    tr:nth-child(odd) {
        background-color: #2E2E2E;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # í‘œ ì¶œë ¥
    st.table(criteria_df)
    
    # ì¤‘ìš”ë„ ì„¤ëª…
    st.markdown("""
    #### ğŸ“ ì¤‘ìš”ë„ ì„¤ëª…
    - â­â­â­ : ìŠ¤ìœ™ì˜ í•µì‹¬ ìš”ì†Œ
    - â­â­ : ë³´ì¡°ì  ì¤‘ìš” ìš”ì†Œ
    """)
    
    st.markdown("---")
    
    if 'evaluations' in analysis_result:
        evaluations = analysis_result['evaluations']
        frames_data = analysis_result['frames']
        key_frames = analysis_result['key_frames']
        
        # ê° ìŠ¤ìœ™ ë‹¨ê³„ë³„ í‰ê°€ í‘œì‹œ
        phase_names = {
            'address': 'ì–´ë“œë ˆìŠ¤ ìì„¸',
            'top': 'íƒ‘ ìì„¸',
            'impact': 'ì„íŒ©íŠ¸ ìì„¸',
            'follow_through': 'íŒ”ë¡œìš° ìŠ¤ë£¨',
            'finish': 'í”¼ë‹ˆì‹œ ìì„¸'
        }
        
        check_names = {
            'Arm Angle Straight': 'íŒ”ì´ ê³§ê²Œ ë»—ì–´ìˆë‚˜ìš”? (165-180ë„)',
            'Posture Stable': 'ìì„¸ê°€ ì•ˆì •ì ì¸ê°€ìš”? (ì²™ì¶” ê°ë„ 30ë„ ì´ìƒ)',
            'Shoulder Rotation Good': 'ì–´ê¹¨ íšŒì „ì´ ì¶©ë¶„í•œê°€ìš”? (80ë„ ì´ìƒ)',
            'Head Stable': 'ë¨¸ë¦¬ê°€ ì•ˆì •ì ì¸ê°€ìš”? (ì›€ì§ì„ 0.1 ì´í•˜)',
            'Hip Rotation Good': 'í™ íšŒì „ì´ ì¶©ë¶„í•œê°€ìš”? (45ë„ ì´ìƒ)',
            'Follow Through Complete': 'íŒ”ë¡œìš° ìŠ¤ë£¨ê°€ ì™„ì„±ë˜ì—ˆë‚˜ìš”? (120ë„ ì´í•˜)',
            'Balance Maintained': 'ê· í˜•ì´ ì˜ ì¡í˜”ë‚˜ìš”? (ë¬´ë¦ ê°ë„ 160ë„ ì´í•˜)',
            'Arm Straight': 'íŒ”ì´ ê³§ê²Œ ë»—ì–´ìˆë‚˜ìš”? (165-180ë„)'
        }
        
        for phase, phase_evaluations in evaluations.items():
            st.markdown(f"### {phase_names.get(phase, phase)}")
            
            # í˜„ì¬ í”„ë ˆì„ì˜ ê°ë„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            frame_idx = key_frames.get(phase, 0)
            current_frame = frames_data[frame_idx] if frame_idx < len(frames_data) else None
            
            # í‰ê°€ ê²°ê³¼ë¥¼ í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            results = []
            for check_name, is_passed in phase_evaluations.items():
                current_value = None
                if current_frame:
                    if check_name in ['Arm Angle Straight', 'Arm Straight']:
                        current_value = current_frame['angles'].get('right_arm', 0)
                    elif check_name == 'Posture Stable':
                        current_value = current_frame['angles'].get('spine_angle', 0)
                    elif check_name == 'Shoulder Rotation Good':
                        current_value = current_frame['angles'].get('shoulder_angle', 0)
                    elif check_name == 'Hip Rotation Good':
                        current_value = current_frame['angles'].get('hip_angle', 0)
                    elif check_name == 'Balance Maintained':
                        current_value = current_frame['angles'].get('right_leg', 0)
                    elif check_name == 'Head Stable':
                        current_value = analysis_result['metrics'].get('head_movement', 0)
                
                result_text = "âœ… ì¢‹ìŠµë‹ˆë‹¤" if is_passed else "âŒ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤"
                if current_value is not None:
                    result_text += f" (í˜„ì¬: {current_value:.1f}Â°)"
                
                results.append({
                    "ì²´í¬ í•­ëª©": check_names.get(check_name, check_name),
                    "ê²°ê³¼": result_text
                })
            
            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
            df = pd.DataFrame(results)
            st.table(df)
            
            # ë‹¨ê³„ë³„ ì¡°ì–¸ ì¶”ê°€
            if not all(phase_evaluations.values()):
                st.markdown("#### ğŸ’¡ ì¡°ì–¸")
                for check_name, is_passed in phase_evaluations.items():
                    if not is_passed:
                        current_value = None
                        if current_frame:
                            if check_name in ['Arm Angle Straight', 'Arm Straight']:
                                current_value = current_frame['angles'].get('right_arm', 0)
                            elif check_name == 'Posture Stable':
                                current_value = current_frame['angles'].get('spine_angle', 0)
                            elif check_name == 'Shoulder Rotation Good':
                                current_value = current_frame['angles'].get('shoulder_angle', 0)
                            elif check_name == 'Hip Rotation Good':
                                current_value = current_frame['angles'].get('hip_angle', 0)
                            elif check_name == 'Balance Maintained':
                                current_value = current_frame['angles'].get('right_leg', 0)
                            elif check_name == 'Head Stable':
                                current_value = analysis_result['metrics'].get('head_movement', 0)
                        
                        advice = get_swing_advice(phase, check_name)
                        if current_value is not None:
                            advice += f" (í˜„ì¬: {current_value:.1f}Â°)"
                        st.info(advice)
            
            # êµ¬ë¶„ì„  ì¶”ê°€
            st.markdown("---")
    else:
        st.warning("í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

def get_swing_advice(phase: str, check_name: str) -> str:
    """ìŠ¤ìœ™ ë‹¨ê³„ì™€ ì²´í¬ í•­ëª©ì— ë”°ë¥¸ ì¡°ì–¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    advice_dict = {
        'address': {
            'Arm Angle Straight': "íŒ”ì„ ë” ê³§ê²Œ í´ë³´ì„¸ìš”. ì´ìƒì ì¸ ê°ë„ëŠ” 165-180ë„ ì…ë‹ˆë‹¤.",
            'Posture Stable': "ìƒì²´ë¥¼ ì•½ê°„ ìˆ™ì´ê³ , ë¬´ê²Œ ì¤‘ì‹¬ì„ ë°œ ì¤‘ì•™ì— ë‘ì–´ ì•ˆì •ì ì¸ ìì„¸ë¥¼ ë§Œë“œì„¸ìš”."
        },
        'top': {
            'Shoulder Rotation Good': "ë°±ìŠ¤ìœ™ ì‹œ ì–´ê¹¨ íšŒì „ì„ ë” í¬ê²Œ í•´ë³´ì„¸ìš”. íŒŒì›Œë¥¼ ìœ„í•´ì„œëŠ” ìµœì†Œ 80ë„ ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.",
            'Head Stable': "ë°±ìŠ¤ìœ™ ì¤‘ì—ë„ ë¨¸ë¦¬ ìœ„ì¹˜ë¥¼ ìµœëŒ€í•œ ê³ ì •í•˜ì„¸ìš”. ì¼ê´€ëœ ìŠ¤ìœ™ì„ ìœ„í•´ ì¤‘ìš”í•©ë‹ˆë‹¤."
        },
        'impact': {
            'Arm Straight': "ì„íŒ©íŠ¸ ì‹œì ì—ì„œ íŒ”ì„ ë” ê³§ê²Œ í´ë³´ì„¸ìš”. ì´ìƒì ì¸ ê°ë„ëŠ” 165-180ë„ ì…ë‹ˆë‹¤.",
            'Hip Rotation Good': "ì„íŒ©íŠ¸ ì‹œ í™ íšŒì „ì„ ë” ì ê·¹ì ìœ¼ë¡œ í•´ë³´ì„¸ìš”. ìµœì†Œ 45ë„ ì´ìƒ íšŒì „ì´ í•„ìš”í•©ë‹ˆë‹¤."
        },
        'follow_through': {
            'Follow Through Complete': "íŒ”ë¡œìš° ìŠ¤ë£¨ ë™ì‘ì„ ë” í¬ê²Œ í•´ë³´ì„¸ìš”. ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.",
            'Balance Maintained': "íŒ”ë¡œìš° ìŠ¤ë£¨ ì‹œ ê· í˜•ì„ ì˜ ì¡ì•„ì£¼ì„¸ìš”. ì²´ì¤‘ ì´ë™ì´ ìì—°ìŠ¤ëŸ¬ì›Œì•¼ í•©ë‹ˆë‹¤."
        },
        'finish': {
            'Follow Through Complete': "í”¼ë‹ˆì‹œ ë™ì‘ì„ ì™„ì„±ë„ ìˆê²Œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”. ìƒì²´ë¥¼ ëª©í‘œ ë°©í–¥ìœ¼ë¡œ íšŒì „ì‹œí‚¤ì„¸ìš”.",
            'Balance Maintained': "í”¼ë‹ˆì‹œ ìì„¸ì—ì„œ ê· í˜•ì„ ì˜ ì¡ì•„ì£¼ì„¸ìš”. ì˜¤ë¥¸ë°œ ì•ˆìª½ìœ¼ë¡œ ì²´ì¤‘ì„ ì´ë™í•˜ì„¸ìš”."
        }
    }
    
    return advice_dict.get(phase, {}).get(check_name, "ìì„¸ë¥¼ ì „ë°˜ì ìœ¼ë¡œ ì ê²€í•´ë³´ì„¸ìš”.")

def create_continuous_overlap_sequence(frames: List[Tuple[str, np.ndarray]]) -> np.ndarray:
    """ì—°ì† ê²¹ì¹¨ ë°©ì‹ìœ¼ë¡œ ìŠ¤ìœ™ ì‹œí€€ìŠ¤ ìƒì„± (ì‚¬ëŒ ì˜ì—­ í¬ë¡­ + ê²¹ì¹¨)"""
    if not frames:
        raise ValueError("í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê° í”„ë ˆì„ì€ ì´ë¯¸ í¬ë¡­ëœ ìƒíƒœë¡œ ì „ë‹¬ë¨
    target_height = 500  # ëª©í‘œ ë†’ì´
    
    # ëª¨ë“  í”„ë ˆì„ì„ ë™ì¼í•œ ë†’ì´ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    resized_frames = []
    for phase, frame in frames:
        h, w = frame.shape[:2]
        scale = target_height / h
        new_width = int(w * scale)
        resized = cv2.resize(frame, (new_width, target_height))
        resized_frames.append((phase, resized))
    
    if not resized_frames:
        raise ValueError("ë¦¬ì‚¬ì´ì¦ˆëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê²¹ì¹¨ ë¹„ìœ¨ (ê° í”„ë ˆì„ì´ ë‹¤ìŒ í”„ë ˆì„ê³¼ ì–¼ë§ˆë‚˜ ê²¹ì¹ ì§€)
    overlap_ratio = 0.3  # 30% ê²¹ì¹¨
    
    # ì „ì²´ ë„ˆë¹„ ê³„ì‚°
    total_width = 0
    frame_widths = [frame.shape[1] for _, frame in resized_frames]
    
    # ì²« ë²ˆì§¸ í”„ë ˆì„ì€ ì „ì²´ ë„ˆë¹„
    total_width += frame_widths[0]
    
    # ë‚˜ë¨¸ì§€ í”„ë ˆì„ë“¤ì€ ê²¹ì¹¨ì„ ê³ ë ¤í•œ ë„ˆë¹„
    for i in range(1, len(frame_widths)):
        total_width += int(frame_widths[i] * (1 - overlap_ratio))
    
    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
    result = np.zeros((target_height, total_width, 3), dtype=np.uint8)
    
    # ì²« ë²ˆì§¸ í”„ë ˆì„ ë°°ì¹˜
    x_offset = 0
    phase, first_frame = resized_frames[0]
    result[:, x_offset:x_offset + first_frame.shape[1]] = first_frame
    
    # ë‹¨ê³„ ë¼ë²¨ ì¶”ê°€ (ì²« ë²ˆì§¸ í”„ë ˆì„)
    cv2.putText(result, phase.upper(), 
               (x_offset + 10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(result, phase.upper(), 
               (x_offset + 10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)
    
    # ë‚˜ë¨¸ì§€ í”„ë ˆì„ë“¤ì„ ê²¹ì³ì„œ ë°°ì¹˜
    for i in range(1, len(resized_frames)):
        phase, frame = resized_frames[i]
        
        # ì´ì „ í”„ë ˆì„ê³¼ ê²¹ì¹˜ë„ë¡ x_offset ê³„ì‚°
        prev_width = resized_frames[i-1][1].shape[1]
        x_offset += int(prev_width * (1 - overlap_ratio))
        
        # ê²¹ì¹˜ëŠ” ì˜ì—­ ê³„ì‚°
        frame_end = x_offset + frame.shape[1]
        if frame_end > total_width:
            frame_end = total_width
            frame = frame[:, :total_width - x_offset]
        
        # ì•ŒíŒŒ ë¸”ë Œë”©ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ê²¹ì¹¨ íš¨ê³¼
        alpha = 0.7  # íˆ¬ëª…ë„
        
        # í˜„ì¬ í”„ë ˆì„ ì˜ì—­
        current_region = result[:, x_offset:frame_end]
        
        if current_region.shape[1] > 0 and frame.shape[1] > 0:
            # ê²¹ì¹˜ëŠ” ë¶€ë¶„ë§Œ ë¸”ë Œë”©
            overlap_width = min(current_region.shape[1], frame.shape[1])
            
            if overlap_width > 0:
                # ì•ˆì „í•œ ì˜ì—­ ì¶”ì¶œ
                safe_current = current_region[:, :overlap_width]
                safe_frame = frame[:, :overlap_width]
                
                # ë†’ì´ê°€ ë‹¤ë¥¸ ê²½ìš° ë§ì¶¤
                if safe_current.shape[0] != safe_frame.shape[0]:
                    min_height = min(safe_current.shape[0], safe_frame.shape[0])
                    safe_current = safe_current[:min_height, :]
                    safe_frame = safe_frame[:min_height, :]
                
                # ì±„ë„ ìˆ˜ í™•ì¸ ë° ë§ì¶¤
                if len(safe_current.shape) == 3 and len(safe_frame.shape) == 3:
                    if safe_current.shape[2] == safe_frame.shape[2]:
                        # ë™ì¼í•œ ì±„ë„ ìˆ˜ì¸ ê²½ìš° ë¸”ë Œë”©
                        try:
                            blended = cv2.addWeighted(
                                safe_current.astype(np.uint8), 
                                1 - alpha, 
                                safe_frame.astype(np.uint8), 
                                alpha, 
                                0
                            )
                            result[:blended.shape[0], x_offset:x_offset + overlap_width] = blended
                        except Exception as e:
                            logger.warning(f"Blending failed, using overlay: {str(e)}")
                            # ë¸”ë Œë”© ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì˜¤ë²„ë ˆì´
                            result[:safe_frame.shape[0], x_offset:x_offset + overlap_width] = safe_frame
                    else:
                        # ì±„ë„ ìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš° ë‹¨ìˆœ ì˜¤ë²„ë ˆì´
                        result[:safe_frame.shape[0], x_offset:x_offset + overlap_width] = safe_frame
                else:
                    # ì°¨ì›ì´ ë‹¤ë¥¸ ê²½ìš° ë‹¨ìˆœ ì˜¤ë²„ë ˆì´
                    result[:safe_frame.shape[0], x_offset:x_offset + overlap_width] = safe_frame
                
                # ê²¹ì¹˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€
                if frame.shape[1] > overlap_width:
                    remaining_width = min(frame.shape[1] - overlap_width, total_width - x_offset - overlap_width)
                    if remaining_width > 0:
                        start_col = x_offset + overlap_width
                        end_col = start_col + remaining_width
                        frame_start_col = overlap_width
                        frame_end_col = overlap_width + remaining_width
                        
                        # ì•ˆì „í•œ ë²”ìœ„ ë‚´ì—ì„œë§Œ ë³µì‚¬
                        if (end_col <= total_width and 
                            frame_end_col <= frame.shape[1] and 
                            frame.shape[0] <= target_height):
                            result[:frame.shape[0], start_col:end_col] = frame[:, frame_start_col:frame_end_col]
        
        # ë‹¨ê³„ ë¼ë²¨ ì¶”ê°€
        label_x = x_offset + frame.shape[1] // 2 - 30
        cv2.putText(result, phase.upper(), 
                   (max(0, label_x), 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(result, phase.upper(), 
                   (max(0, label_x), 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)
    
    return result

def auto_crop_person_area(frame: np.ndarray, landmarks_data: Dict) -> np.ndarray:
    """ëœë“œë§ˆí¬ ë°ì´í„°ë¥¼ ì´ìš©í•´ ì‚¬ëŒ ì˜ì—­ì„ ìë™ìœ¼ë¡œ í¬ë¡­í•©ë‹ˆë‹¤."""
    try:
        h, w = frame.shape[:2]
        
        # ì£¼ìš” ëœë“œë§ˆí¬ë§Œ ì‚¬ìš© (ì‹ ë¢°ì„± ë†’ì€ í¬ì¸íŠ¸ë“¤)
        key_landmarks = [
            'left_shoulder', 'right_shoulder',
            'left_elbow', 'right_elbow', 
            'left_wrist', 'right_wrist',
            'left_hip', 'right_hip',
            'left_knee', 'right_knee',
            'left_ankle', 'right_ankle'
        ]
        
        valid_points = []
        for landmark_name in key_landmarks:
            if landmark_name in landmarks_data and landmarks_data[landmark_name]:
                point = landmarks_data[landmark_name]
                if len(point) >= 2:
                    # ì¢Œí‘œê°€ 0-1 ì‚¬ì´ì˜ ì •ê·œí™”ëœ ê°’ì¸ì§€ í™•ì¸
                    x, y = point[0], point[1]
                    
                    # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                    if 0 <= x <= 1 and 0 <= y <= 1:
                        pixel_x = int(x * w)
                        pixel_y = int(y * h)
                    else:
                        # ì´ë¯¸ í”½ì…€ ì¢Œí‘œì¸ ê²½ìš°
                        pixel_x = int(x)
                        pixel_y = int(y)
                    
                    # ìœ íš¨í•œ ë²”ìœ„ ë‚´ì˜ ì¢Œí‘œë§Œ ì¶”ê°€
                    if 0 <= pixel_x < w and 0 <= pixel_y < h:
                        valid_points.append([pixel_x, pixel_y])
        
        if len(valid_points) < 4:  # ìµœì†Œ 4ê°œì˜ ìœ íš¨í•œ í¬ì¸íŠ¸ê°€ í•„ìš”
            logger.warning(f"Not enough valid landmarks: {len(valid_points)}")
            # ì—£ì§€ ê°ì§€ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´
            return crop_using_edge_detection(frame)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        points = np.array(valid_points)
        min_x, min_y = np.min(points, axis=0)
        max_x, max_y = np.max(points, axis=0)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ê³„ì‚°
        bbox_width = max_x - min_x
        bbox_height = max_y - min_y
        
        # ì—¬ìœ  ê³µê°„ ì¶”ê°€ (ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ì˜ 10%)
        padding_x = max(int(bbox_width * 0.1), 20)  # ìµœì†Œ 20í”½ì…€
        padding_y = max(int(bbox_height * 0.1), 20)  # ìµœì†Œ 20í”½ì…€
        
        # ìµœì¢… í¬ë¡­ ì˜ì—­ ê³„ì‚°
        x1 = max(0, min_x - padding_x)
        y1 = max(0, min_y - padding_y)
        x2 = min(w, max_x + padding_x)
        y2 = min(h, max_y + padding_y)
        
        # ìµœì†Œ í¬ê¸° ë³´ì¥ (ë„ˆë¬´ ì‘ìœ¼ë©´ í™•ì¥)
        min_width = 150
        min_height = 200
        
        if x2 - x1 < min_width:
            center_x = (x1 + x2) // 2
            half_width = min_width // 2
            x1 = max(0, center_x - half_width)
            x2 = min(w, center_x + half_width)
        
        if y2 - y1 < min_height:
            center_y = (y1 + y2) // 2
            half_height = min_height // 2
            y1 = max(0, center_y - half_height)
            y2 = min(h, center_y + half_height)
        
        logger.debug(f"Crop area: ({x1}, {y1}) to ({x2}, {y2}) from frame size ({w}, {h})")
        
        # í¬ë¡­ ì‹¤í–‰
        cropped = frame[y1:y2, x1:x2]
        
        # í¬ë¡­ëœ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
        if cropped.shape[0] < 50 or cropped.shape[1] < 50:
            logger.warning("Cropped image too small, returning original")
            return frame
        
        return cropped
        
    except Exception as e:
        logger.error(f"Error in auto_crop_person_area: {str(e)}")
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì—£ì§€ ê°ì§€ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´
        return crop_using_edge_detection(frame)

def crop_using_edge_detection(frame: np.ndarray) -> np.ndarray:
    """ì—£ì§€ ê°ì§€ë¥¼ ì´ìš©í•œ ì‚¬ëŒ ì˜ì—­ í¬ë¡­ (ëŒ€ì²´ ë°©ë²•)"""
    try:
        h, w = frame.shape[:2]
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # ì—£ì§€ ê°ì§€
        edges = cv2.Canny(blurred, 50, 150)
        
        # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì—£ì§€ ì—°ê²°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
        
        # ì»¨íˆ¬ì–´ ì°¾ê¸°
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            # ê°€ì¥ í° ì»¨íˆ¬ì–´ë“¤ ì¤‘ì—ì„œ ì¤‘ì•™ì— ê°€ê¹Œìš´ ê²ƒ ì„ íƒ
            large_contours = [c for c in contours if cv2.contourArea(c) > 1000]
            
            if large_contours:
                # ì¤‘ì•™ì— ê°€ì¥ ê°€ê¹Œìš´ í° ì»¨íˆ¬ì–´ ì„ íƒ
                center_x, center_y = w // 2, h // 2
                best_contour = min(large_contours, 
                                 key=lambda c: np.linalg.norm(
                                     np.array(cv2.boundingRect(c)[:2]) + 
                                     np.array(cv2.boundingRect(c)[2:]) // 2 - 
                                     np.array([center_x, center_y])
                                 ))
                
                x, y, cw, ch = cv2.boundingRect(best_contour)
                
                # ì—¬ìœ  ê³µê°„ ì¶”ê°€
                padding = 30
                x = max(0, x - padding)
                y = max(0, y - padding)
                cw = min(w - x, cw + 2 * padding)
                ch = min(h - y, ch + 2 * padding)
                
                logger.debug(f"Edge detection crop: ({x}, {y}) size ({cw}, {ch})")
                return frame[y:y+ch, x:x+cw]
        
        # ì»¨íˆ¬ì–´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì¤‘ì•™ ë¶€ë¶„ í¬ë¡­
        logger.warning("No suitable contours found, using center crop")
        crop_w = int(w * 0.7)  # 70% ë„ˆë¹„
        crop_h = int(h * 0.9)  # 90% ë†’ì´
        start_x = (w - crop_w) // 2
        start_y = (h - crop_h) // 2
        
        return frame[start_y:start_y+crop_h, start_x:start_x+crop_w]
        
    except Exception as e:
        logger.error(f"Error in crop_using_edge_detection: {str(e)}")
        # ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ ì¤‘ì•™ í¬ë¡­
        h, w = frame.shape[:2]
        crop_w = int(w * 0.8)
        crop_h = int(h * 0.9)
        start_x = (w - crop_w) // 2
        start_y = (h - crop_h) // 2
        return frame[start_y:start_y+crop_h, start_x:start_x+crop_w]

def create_swing_sequence_local(video_path: str, key_frames: Dict[str, int], 
                               output_path: str = "swing_sequence.jpg", 
                               overlap_mode: str = "overlap") -> str:
    """ë¡œì»¬ ìŠ¤ìœ™ ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜"""
    try:
        cap = cv2.VideoCapture(video_path)
        
        # í‚¤ í”„ë ˆì„ ìˆœì„œ ì •ì˜
        if overlap_mode == "continuous":
            # ì—°ì† ê²¹ì¹¨ìš© - ë” ë§ì€ í”„ë ˆì„ ì‚¬ìš©
            frame_keys = ['address', 'takeaway', 'backswing_start', 'backswing_mid', 'top', 
                         'transition', 'downswing_start', 'downswing_mid', 'impact', 
                         'follow_start', 'follow_mid', 'finish']
        else:
            # ê¸°ë³¸ 5ë‹¨ê³„
            frame_keys = ['address', 'backswing', 'top', 'impact', 'follow_through']
        
        frames = []
        
        for phase in frame_keys:
            frame_idx = key_frames.get(phase)
            if frame_idx is not None:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                
                if ret:
                    # í”„ë ˆì„ í¬ê¸° ì¡°ì •
                    height, width = frame.shape[:2]
                    if width > 600:
                        scale = 600 / width
                        new_width = int(width * scale)
                        new_height = int(height * scale)
                        frame = cv2.resize(frame, (new_width, new_height))
                    
                    frames.append((phase, frame))
        
        cap.release()
        
        if not frames:
            return None
        
        if overlap_mode == "continuous":
            result_img = create_continuous_overlap_sequence(frames)
        else:
            result_img = create_overlapped_sequence(frames)
        
        if result_img is not None:
            cv2.imwrite(output_path, result_img)
            return output_path
        
        return None
        
    except Exception as e:
        logger.error(f"Error creating swing sequence: {e}")
        return None

def create_detailed_phase_analysis_local(video_path: str, key_frames: Dict[str, int], 
                                       output_path: str = "detailed_swing_phases.jpg") -> str:
    """ë¡œì»¬ ì„¸ë¶„í™” í¬ì¦ˆ ë¶„ì„ ìƒì„± í•¨ìˆ˜"""
    try:
        cap = cv2.VideoCapture(video_path)
        
        # ëª¨ë“  ì„¸ë¶„í™”ëœ ë‹¨ê³„ ì •ì˜
        phases = [
            ('address', 'ì–´ë“œë ˆìŠ¤', (0, 255, 0)),
            ('takeaway', 'í…Œì´í¬ì–´ì›¨ì´', (255, 255, 0)),
            ('backswing_start', 'ë°±ìŠ¤ìœ™ ì‹œì‘', (255, 200, 0)),
            ('backswing_mid', 'ë°±ìŠ¤ìœ™ ì¤‘ê°„', (255, 150, 0)),
            ('top', 'íƒ‘', (255, 0, 0)),
            ('transition', 'íŠ¸ëœì§€ì…˜', (255, 0, 100)),
            ('downswing_start', 'ë‹¤ìš´ìŠ¤ìœ™ ì‹œì‘', (255, 0, 200)),
            ('downswing_mid', 'ë‹¤ìš´ìŠ¤ìœ™ ì¤‘ê°„', (200, 0, 255)),
            ('impact', 'ì„íŒ©íŠ¸', (100, 0, 255)),
            ('follow_start', 'íŒ”ë¡œìš° ì‹œì‘', (0, 100, 255)),
            ('follow_mid', 'íŒ”ë¡œìš° ì¤‘ê°„', (0, 200, 255)),
            ('finish', 'í”¼ë‹ˆì‹œ', (0, 255, 255))
        ]
        
        frames = []
        
        for phase_key, phase_name, color in phases:
            frame_idx = key_frames.get(phase_key)
            if frame_idx is not None:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                
                if ret:
                    # í”„ë ˆì„ í¬ê¸° í‘œì¤€í™”
                    target_height = 300
                    aspect_ratio = frame.shape[1] / frame.shape[0]
                    target_width = int(target_height * aspect_ratio)
                    frame = cv2.resize(frame, (target_width, target_height))
                    
                    frames.append((phase_name, frame))
        
        cap.release()
        
        if not frames:
            return None
        
        # ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë°°ì¹˜ (4x3)
        rows = 3
        cols = 4
        
        # í”„ë ˆì„ í¬ê¸° í†µì¼
        if frames:
            max_height = max(frame.shape[0] for _, frame in frames)
            max_width = max(frame.shape[1] for _, frame in frames)
            
            normalized_frames = []
            for phase_name, frame in frames:
                # íŒ¨ë”© ì¶”ê°€í•˜ì—¬ í¬ê¸° í†µì¼
                padded = np.zeros((max_height, max_width, 3), dtype=np.uint8)
                h, w = frame.shape[:2]
                y_offset = (max_height - h) // 2
                x_offset = (max_width - w) // 2
                padded[y_offset:y_offset+h, x_offset:x_offset+w] = frame
                
                # ë‹¨ê³„ëª… ì¶”ê°€
                cv2.putText(padded, phase_name, (10, 30), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                normalized_frames.append(padded)
            
            # ë¹ˆ í”„ë ˆì„ìœ¼ë¡œ íŒ¨ë”©
            while len(normalized_frames) < rows * cols:
                empty_frame = np.zeros((max_height, max_width, 3), dtype=np.uint8)
                normalized_frames.append(empty_frame)
            
            # ê·¸ë¦¬ë“œ ìƒì„±
            grid_rows = []
            for i in range(rows):
                row_frames = normalized_frames[i*cols:(i+1)*cols]
                grid_row = np.hstack(row_frames)
                grid_rows.append(grid_row)
            
            final_grid = np.vstack(grid_rows)
            
            # ì œëª© ì¶”ê°€
            title_height = 60
            title_img = np.zeros((title_height, final_grid.shape[1], 3), dtype=np.uint8)
            cv2.putText(title_img, "Detailed Swing Phase Analysis", 
                       (final_grid.shape[1]//2 - 250, 35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
            
            final_result = np.vstack([title_img, final_grid])
            
            # ì´ë¯¸ì§€ ì €ì¥
            cv2.imwrite(output_path, final_result)
            return output_path
        
        return None
        
    except Exception as e:
        logger.error(f"Error creating detailed phase analysis: {e}")
        return None

if __name__ == "__main__":
    main() 